{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adb6a832",
   "metadata": {
    "papermill": {
     "duration": 0.007659,
     "end_time": "2023-09-29T06:12:55.783781",
     "exception": false,
     "start_time": "2023-09-29T06:12:55.776122",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "<div style=\"padding:10px; \n",
    "            color:black;\n",
    "            margin:10px;\n",
    "            font-size:150%;\n",
    "            display:block;\n",
    "            border-radius:1px;\n",
    "            border-style: solid;\n",
    "            border-color:skyblue;\n",
    "            background-color:#00EFFF;\n",
    "            overflow:hidden;\">\n",
    "    <center>\n",
    "        <a id='top'></a>\n",
    "        <b style=\"color:black\">Table of Contents</b>\n",
    "    </center>\n",
    "    <ul>\n",
    "        <li>\n",
    "            <a href=\"#1\" style=\"color:black\">1 -  Overview</a>\n",
    "        </li>\n",
    "        <li>\n",
    "            <a href=\"#2\" style=\"color:black\">2 -  Imports</a>\n",
    "        </li>\n",
    "        <li>\n",
    "            <a href=\"#3\" style=\"color:black\">3 - Data Loading and Analysis</a>\n",
    "        </li>\n",
    "         <li>\n",
    "            <a href=\"#4\" style=\"color:black\">4 - Data Preprocessing</a>\n",
    "        </li>\n",
    "            <li>\n",
    "            <a href=\"#5\" style=\"color:black\">5 - Model Implementation </a>\n",
    "        </li>\n",
    "        <li>\n",
    "            <a href=\"#6\" style=\"color:black\">6 - Evaluation</a>\n",
    "        </li>\n",
    "        <li>\n",
    "            <a href=\"#7\" style=\"color:black\">7 - Thank you</a>\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>\n",
    "\n",
    "\n",
    "<a id=\"1\"></a>\n",
    "<h1 style='background:#00EFFF;border:0; color:black;\n",
    "    box-shadow: 10px 10px 5px 0px rgba(0,0,0,0.75);\n",
    "    transform: rotateX(10deg);\n",
    "    '><center style='color: #000000;'>Overview</center></h1>\n",
    "\n",
    "\n",
    "# Overview\n",
    "\n",
    "## Implementing Machine and Deep Learning Algorithms from Scratch\n",
    "\n",
    "**In this series of notebooks, we'll be implementing Machine and Deep Learning algorithms from scratch. We will strive to avoid using for loops and instead utilize [Vectorized Implementations](https://www.kaggle.com/code/fareselmenshawii/vectorization).**\n",
    "\n",
    "**We will primarily rely on the following libraries:**\n",
    "- **NumPy for Linear Algebra**\n",
    "- **Pandas for Data Analysis**\n",
    "- **Plotly for visualization**\n",
    "\n",
    "**The first learning algorithm we'll explore is Linear Regression.**\n",
    "**Let's get started!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13340cc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "86e250f4",
   "metadata": {
    "papermill": {
     "duration": 0.005711,
     "end_time": "2023-09-29T06:12:55.795998",
     "exception": false,
     "start_time": "2023-09-29T06:12:55.790287",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id=\"2\"></a>\n",
    "<h1 style='background:#00EFFF;border:0; color:black;\n",
    "    box-shadow: 10px 10px 5px 0px rgba(0,0,0,0.75);\n",
    "    transform: rotateX(10deg);\n",
    "    '><center style='color: #000000;'>Imports</center></h1>\n",
    "\n",
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcbbc819",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-29T06:12:55.812120Z",
     "iopub.status.busy": "2023-09-29T06:12:55.811398Z",
     "iopub.status.idle": "2023-09-29T06:12:57.521132Z",
     "shell.execute_reply": "2023-09-29T06:12:57.519314Z"
    },
    "papermill": {
     "duration": 1.721101,
     "end_time": "2023-09-29T06:12:57.524612",
     "exception": false,
     "start_time": "2023-09-29T06:12:55.803511",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b8672aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0656d4",
   "metadata": {
    "papermill": {
     "duration": 0.006087,
     "end_time": "2023-09-29T06:12:57.536728",
     "exception": false,
     "start_time": "2023-09-29T06:12:57.530641",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id=\"3\"></a>\n",
    "<h1 style='background:#00EFFF;border:0; color:black;\n",
    "    box-shadow: 10px 10px 5px 0px rgba(0,0,0,0.75);\n",
    "    transform: rotateX(10deg);\n",
    "    '><center style='color: #000000;'>Data Loading and Analysis</center></h1>\n",
    "\n",
    "# Data Loading and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f3d23f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-29T06:12:57.550996Z",
     "iopub.status.busy": "2023-09-29T06:12:57.550168Z",
     "iopub.status.idle": "2023-09-29T06:12:57.590638Z",
     "shell.execute_reply": "2023-09-29T06:12:57.589180Z"
    },
    "papermill": {
     "duration": 0.050847,
     "end_time": "2023-09-29T06:12:57.593600",
     "exception": false,
     "start_time": "2023-09-29T06:12:57.542753",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the training and test datasets\n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "# Remove rows with missing values\n",
    "train_data = train_data.dropna()\n",
    "test_data = test_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65214d47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-29T06:12:57.608529Z",
     "iopub.status.busy": "2023-09-29T06:12:57.607643Z",
     "iopub.status.idle": "2023-09-29T06:12:57.627558Z",
     "shell.execute_reply": "2023-09-29T06:12:57.626223Z"
    },
    "papermill": {
     "duration": 0.031853,
     "end_time": "2023-09-29T06:12:57.631372",
     "exception": false,
     "start_time": "2023-09-29T06:12:57.599519",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "x",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "y",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "9de6e9c3-8d85-4855-9865-71d83369ce28",
       "rows": [
        [
         "0",
         "24.0",
         "21.54945196"
        ],
        [
         "1",
         "50.0",
         "47.46446305"
        ],
        [
         "2",
         "15.0",
         "17.21865634"
        ],
        [
         "3",
         "38.0",
         "36.58639803"
        ],
        [
         "4",
         "87.0",
         "87.28898389"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.0</td>\n",
       "      <td>21.549452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50.0</td>\n",
       "      <td>47.464463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.0</td>\n",
       "      <td>17.218656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38.0</td>\n",
       "      <td>36.586398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87.0</td>\n",
       "      <td>87.288984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      x          y\n",
       "0  24.0  21.549452\n",
       "1  50.0  47.464463\n",
       "2  15.0  17.218656\n",
       "3  38.0  36.586398\n",
       "4  87.0  87.288984"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a164650",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-29T06:12:57.647812Z",
     "iopub.status.busy": "2023-09-29T06:12:57.646947Z",
     "iopub.status.idle": "2023-09-29T06:12:58.928388Z",
     "shell.execute_reply": "2023-09-29T06:12:58.927399Z"
    },
    "papermill": {
     "duration": 1.293896,
     "end_time": "2023-09-29T06:12:58.931187",
     "exception": false,
     "start_time": "2023-09-29T06:12:57.637291",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "x=%{x}<br>y=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "rgb(76,114,176)",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": [
          24,
          50,
          15,
          38,
          87,
          36,
          12,
          81,
          25,
          5,
          16,
          16,
          24,
          39,
          54,
          60,
          26,
          73,
          29,
          31,
          68,
          87,
          58,
          54,
          84,
          58,
          49,
          20,
          90,
          48,
          4,
          25,
          42,
          0,
          60,
          93,
          39,
          7,
          21,
          68,
          84,
          0,
          58,
          19,
          36,
          19,
          59,
          51,
          19,
          33,
          85,
          44,
          5,
          59,
          14,
          9,
          75,
          69,
          10,
          17,
          58,
          74,
          21,
          51,
          19,
          50,
          24,
          0,
          12,
          75,
          21,
          64,
          5,
          58,
          32,
          41,
          7,
          4,
          5,
          49,
          90,
          3,
          11,
          32,
          83,
          25,
          83,
          26,
          76,
          95,
          53,
          77,
          42,
          25,
          54,
          55,
          0,
          73,
          35,
          86,
          90,
          13,
          46,
          46,
          32,
          8,
          71,
          28,
          24,
          56,
          49,
          79,
          90,
          89,
          41,
          27,
          58,
          26,
          31,
          70,
          71,
          39,
          7,
          48,
          56,
          45,
          41,
          3,
          37,
          24,
          68,
          47,
          27,
          68,
          74,
          95,
          79,
          21,
          95,
          54,
          56,
          80,
          26,
          25,
          8,
          95,
          94,
          54,
          7,
          99,
          36,
          48,
          65,
          42,
          93,
          86,
          26,
          51,
          100,
          94,
          6,
          24,
          75,
          7,
          53,
          73,
          16,
          80,
          77,
          89,
          80,
          55,
          19,
          56,
          47,
          56,
          2,
          82,
          57,
          44,
          26,
          52,
          41,
          44,
          3,
          31,
          97,
          21,
          17,
          7,
          61,
          10,
          52,
          10,
          65,
          71,
          4,
          24,
          26,
          51,
          42,
          62,
          74,
          77,
          3,
          50,
          24,
          37,
          58,
          52,
          27,
          14,
          100,
          72,
          5,
          71,
          54,
          84,
          42,
          54,
          74,
          54,
          53,
          78,
          97,
          49,
          71,
          48,
          51,
          89,
          99,
          93,
          49,
          18,
          65,
          83,
          100,
          41,
          52,
          29,
          97,
          7,
          51,
          58,
          50,
          67,
          89,
          76,
          35,
          99,
          31,
          52,
          11,
          66,
          50,
          39,
          60,
          35,
          53,
          14,
          49,
          16,
          76,
          13,
          51,
          70,
          98,
          86,
          100,
          46,
          51,
          50,
          91,
          48,
          81,
          38,
          40,
          79,
          96,
          60,
          70,
          44,
          11,
          6,
          5,
          72,
          55,
          95,
          41,
          25,
          1,
          55,
          4,
          48,
          55,
          75,
          68,
          100,
          25,
          75,
          34,
          38,
          92,
          21,
          88,
          75,
          76,
          44,
          10,
          21,
          16,
          32,
          13,
          26,
          70,
          77,
          77,
          88,
          35,
          24,
          17,
          91,
          32,
          36,
          89,
          69,
          30,
          6,
          22,
          67,
          9,
          74,
          50,
          85,
          3,
          0,
          59,
          62,
          17,
          90,
          23,
          19,
          93,
          14,
          58,
          87,
          37,
          20,
          35,
          63,
          56,
          62,
          98,
          90,
          51,
          93,
          22,
          38,
          13,
          98,
          99,
          31,
          94,
          73,
          37,
          23,
          11,
          88,
          47,
          79,
          91,
          71,
          10,
          39,
          92,
          99,
          28,
          32,
          32,
          75,
          99,
          27,
          64,
          98,
          38,
          46,
          13,
          96,
          9,
          34,
          49,
          1,
          50,
          94,
          27,
          20,
          12,
          45,
          91,
          61,
          10,
          47,
          33,
          84,
          24,
          48,
          48,
          9,
          93,
          99,
          8,
          20,
          38,
          78,
          81,
          42,
          95,
          78,
          44,
          68,
          87,
          58,
          52,
          26,
          75,
          48,
          71,
          77,
          34,
          24,
          70,
          29,
          76,
          98,
          28,
          87,
          9,
          87,
          33,
          64,
          17,
          49,
          95,
          75,
          89,
          81,
          25,
          47,
          50,
          5,
          68,
          84,
          8,
          41,
          26,
          89,
          78,
          34,
          92,
          27,
          12,
          2,
          22,
          0,
          26,
          50,
          84,
          70,
          66,
          42,
          19,
          94,
          71,
          19,
          16,
          49,
          29,
          29,
          86,
          50,
          86,
          30,
          23,
          20,
          16,
          57,
          8,
          8,
          62,
          55,
          30,
          86,
          62,
          51,
          61,
          86,
          61,
          21,
          81,
          97,
          5,
          61,
          47,
          98,
          30,
          63,
          0,
          100,
          18,
          30,
          98,
          16,
          22,
          55,
          43,
          75,
          91,
          46,
          85,
          55,
          36,
          49,
          94,
          43,
          22,
          37,
          24,
          95,
          61,
          75,
          68,
          58,
          5,
          53,
          80,
          83,
          25,
          34,
          26,
          90,
          60,
          49,
          19,
          92,
          29,
          8,
          57,
          29,
          19,
          81,
          50,
          15,
          70,
          39,
          43,
          21,
          98,
          86,
          16,
          25,
          31,
          93,
          67,
          49,
          25,
          88,
          54,
          21,
          8,
          32,
          35,
          67,
          90,
          59,
          15,
          67,
          42,
          44,
          77,
          68,
          36,
          11,
          10,
          65,
          98,
          98,
          49,
          31,
          56,
          70,
          91,
          25,
          54,
          39,
          91,
          3,
          22,
          2,
          2,
          65,
          71,
          42,
          76,
          43,
          8,
          86,
          87,
          3,
          58,
          62,
          89,
          95,
          28,
          0,
          1,
          49,
          21,
          46,
          11,
          89,
          37,
          29,
          44,
          96,
          16,
          74,
          35,
          42,
          16,
          56,
          18,
          100,
          54,
          92,
          63,
          81,
          73,
          48,
          1,
          85,
          14,
          25,
          45,
          98,
          97,
          58,
          93,
          88,
          89,
          47,
          6,
          34,
          30,
          16,
          86,
          40,
          52,
          15,
          4,
          95,
          99,
          35,
          58,
          10,
          16,
          53,
          58,
          42,
          24,
          84,
          64,
          12,
          61,
          75,
          15,
          100,
          43,
          13,
          48,
          45,
          52,
          34,
          30,
          65,
          100,
          67,
          99,
          45,
          87,
          73,
          9,
          81,
          72,
          81,
          58,
          93,
          82,
          66,
          97
         ],
         "xaxis": "x",
         "y": [
          21.54945196,
          47.46446305,
          17.21865634,
          36.58639803,
          87.28898389,
          32.46387493,
          10.78089683,
          80.7633986,
          24.61215147,
          6.963319071,
          11.23757338,
          13.53290206,
          24.60323899,
          39.40049976,
          48.43753838,
          61.69900319,
          26.92832418,
          70.4052055,
          29.34092408,
          25.30895192,
          69.02934339,
          84.99484703,
          57.04310305,
          50.5921991,
          83.02772202,
          57.05752706,
          47.95883341,
          24.34226432,
          94.68488281,
          48.03970696,
          7.08132338,
          21.99239907,
          42.33151664,
          0.329089443,
          61.92303698,
          91.17716423,
          39.45358014,
          5.996069607,
          22.59015942,
          61.18044414,
          85.02778957,
          -1.28631089,
          61.94273962,
          21.96033347,
          33.66194193,
          17.60946242,
          58.5630564,
          52.82390762,
          22.1363481,
          35.07467353,
          86.18822311,
          42.63227697,
          4.09817744,
          61.2229864,
          17.70677576,
          11.85312574,
          80.23051695,
          62.64931741,
          9.616859804,
          20.02797699,
          61.7510743,
          71.61010303,
          23.77154623,
          51.90142035,
          22.66073682,
          50.02897927,
          26.68794368,
          0.376911899,
          6.806419002,
          77.33986001,
          28.90260209,
          66.7346608,
          0.707510638,
          57.07748383,
          28.41453196,
          44.46272123,
          7.459605998,
          2.316708112,
          4.928546187,
          52.50336074,
          91.19109623,
          8.489164326,
          6.963371967,
          31.97989959,
          81.4281205,
          22.62365422,
          78.52505087,
          25.80714057,
          73.51081775,
          91.775467,
          49.21863516,
          80.50445387,
          50.05636123,
          25.46292549,
          55.32164264,
          59.1244888,
          1.100686692,
          71.98020786,
          30.13666408,
          83.88427405,
          89.91004752,
          8.335654576,
          47.88388961,
          45.00397413,
          31.15664574,
          9.190375682,
          74.83135003,
          30.23177607,
          24.21914027,
          57.87219151,
          50.61728392,
          78.67470043,
          86.236707,
          89.10409255,
          43.26595082,
          26.68273277,
          59.46383041,
          28.90055826,
          31.300416,
          71.1433266,
          68.4739206,
          39.98238856,
          4.075776144,
          47.85817542,
          51.20390217,
          43.9367213,
          38.13626679,
          3.574661632,
          36.4139958,
          22.21908523,
          63.5312572,
          49.86702787,
          21.53140009,
          64.05710234,
          70.77549842,
          92.15749762,
          81.22259156,
          25.10114067,
          94.08853397,
          53.25166165,
          59.16236621,
          75.24148428,
          28.22325833,
          25.33323728,
          6.364615703,
          95.4609216,
          88.64183756,
          58.70318693,
          6.815491279,
          99.40394676,
          32.77049249,
          47.0586788,
          60.53321778,
          40.30929858,
          89.42222685,
          86.82132066,
          26.11697543,
          53.26657596,
          96.62327888,
          95.78441027,
          6.047286687,
          24.47387908,
          75.96844763,
          3.829381009,
          52.51703683,
          72.80457527,
          14.10999096,
          80.86087062,
          77.01988215,
          86.26972444,
          77.13735466,
          51.47649476,
          17.34557531,
          57.72853572,
          44.15029394,
          59.24362743,
          -1.053275611,
          86.79002254,
          60.14031858,
          44.04222058,
          24.5227488,
          52.95305521,
          43.16133498,
          45.67562576,
          -2.830749501,
          29.19693178,
          96.49812401,
          22.5453232,
          20.10741433,
          4.035430253,
          61.14568518,
          13.97163653,
          55.34529893,
          12.18441166,
          64.00077658,
          70.3188322,
          -0.936895047,
          18.91422276,
          23.87590331,
          47.5775361,
          43.2736092,
          66.48278755,
          75.72605529,
          80.59643338,
          -2.235879852,
          47.04654956,
          21.59635575,
          32.87558963,
          57.95782956,
          52.24760027,
          24.58286902,
          12.12573805,
          100.0158026,
          74.04682658,
          1.611947467,
          70.36836307,
          52.26831735,
          83.1286166,
          43.64765048,
          49.44785426,
          72.6356699,
          52.78130641,
          57.11195136,
          79.1050629,
          101.6228548,
          53.5825402,
          68.92139297,
          46.9666961,
          51.02642868,
          85.52073551,
          99.51685756,
          94.63911256,
          46.78357742,
          21.21321959,
          58.37266004,
          87.22059677,
          102.4967859,
          43.88314335,
          53.06655757,
          26.33464785,
          98.52008934,
          9.400497579,
          52.94026699,
          53.83020877,
          45.94511142,
          65.0132736,
          86.5069584,
          75.63280796,
          36.78035027,
          100.5328916,
          29.04466136,
          51.70352433,
          9.199954718,
          71.70015848,
          49.82634062,
          37.49971096,
          53.65084683,
          33.92561965,
          49.92639685,
          8.148154262,
          49.72359037,
          16.16712757,
          75.30033002,
          9.577368568,
          48.38088357,
          72.95331671,
          92.59573853,
          88.85523586,
          99.00361771,
          45.09439571,
          46.94362684,
          48.33449605,
          94.92329574,
          47.78165248,
          81.28960746,
          37.83155021,
          39.69185252,
          76.92664854,
          88.02990531,
          56.99178872,
          72.58929383,
          44.98103442,
          11.99017641,
          1.919513328,
          1.628826073,
          66.27746655,
          57.53887255,
          94.70291077,
          41.21469904,
          25.04169243,
          3.778209914,
          50.50711779,
          9.682408486,
          48.88147608,
          54.40348599,
          71.70233156,
          69.35848388,
          99.98491591,
          26.03323718,
          75.48910307,
          36.59623056,
          40.95102191,
          86.78316267,
          15.50701184,
          85.86077871,
          79.20610113,
          80.80643766,
          48.59717283,
          13.93415049,
          27.3051179,
          14.00226297,
          33.67416,
          13.11612884,
          24.76649193,
          73.68477876,
          77.53149541,
          76.24503196,
          88.0578931,
          35.02445799,
          21.65857739,
          17.33681562,
          94.36778957,
          33.43396307,
          32.52179399,
          90.57741298,
          71.25634126,
          31.23212856,
          5.398840061,
          18.56241391,
          71.97121038,
          5.225759566,
          73.5964342,
          49.76948983,
          82.69087513,
          1.652309089,
          -3.836652144,
          62.03811556,
          61.26514581,
          13.24991628,
          88.61672694,
          21.13655528,
          23.85017475,
          92.01203405,
          10.26712261,
          54.14681616,
          87.00645713,
          37.69447352,
          19.62278654,
          34.78561007,
          62.03190983,
          52.67003801,
          58.09031476,
          97.19448821,
          90.50155298,
          50.5123462,
          94.45211871,
          21.10794636,
          37.36298431,
          10.28574844,
          96.04932416,
          100.0953697,
          30.6063167,
          96.19000542,
          71.30828034,
          34.59311043,
          19.02332876,
          10.76669688,
          90.5799868,
          48.71787679,
          78.74139764,
          85.23492274,
          71.65789964,
          8.938990554,
          39.89606046,
          91.85091116,
          99.11200375,
          26.22196486,
          33.21584226,
          35.72392691,
          76.88604495,
          99.30874567,
          25.77161074,
          67.85169407,
          98.50371084,
          31.11331895,
          45.51171028,
          12.65537808,
          95.56065366,
          9.526431641,
          36.10893209,
          46.43628318,
          -3.83998112,
          48.97302037,
          93.25305499,
          23.47650968,
          17.13551132,
          14.55896144,
          41.53992729,
          91.64730552,
          66.16652565,
          9.230857489,
          47.41377893,
          34.76441561,
          86.10796637,
          21.81267954,
          48.89963951,
          46.78108638,
          12.91328547,
          94.55203143,
          94.97068753,
          2.379172481,
          21.47982988,
          35.79795462,
          82.0763803,
          78.87097714,
          47.2492425,
          96.18852325,
          78.38491927,
          42.94274064,
          64.43231595,
          84.21191485,
          57.3069783,
          52.52101436,
          25.7440243,
          75.42283401,
          53.62523007,
          75.14466308,
          74.12151511,
          36.24807243,
          20.21665898,
          66.94758118,
          34.07278254,
          73.13850045,
          92.85929155,
          28.36793808,
          85.59308727,
          10.68453755,
          86.10708624,
          33.22031418,
          66.09563422,
          19.30486546,
          48.84542083,
          93.73176312,
          75.45758614,
          91.24239226,
          87.15690853,
          25.53752833,
          46.06629478,
          49.65277661,
          7.382244165,
          71.11189935,
          83.50570521,
          8.791139893,
          33.30638903,
          26.40362524,
          91.72960726,
          82.53030719,
          36.67762733,
          86.98450355,
          32.34784175,
          16.78353974,
          1.576584383,
          17.4618141,
          2.116113029,
          24.34804332,
          48.29491198,
          85.52145453,
          73.71434779,
          63.15189497,
          38.46213684,
          19.47100788,
          94.07428225,
          67.92051286,
          22.58096241,
          16.01629889,
          48.43307886,
          29.6673599,
          26.65566328,
          86.28206739,
          50.82304924,
          88.57251713,
          32.59980745,
          21.02469368,
          20.72894979,
          20.38051187,
          57.25180153,
          6.967537054,
          10.240085,
          64.94841088,
          55.35893915,
          31.24365589,
          90.72048818,
          58.750127,
          55.85003198,
          60.19925869,
          85.03295412,
          60.38823085,
          18.44679787,
          82.18839247,
          94.2963344,
          7.682024586,
          61.01858089,
          53.60562216,
          94.47728801,
          27.9645947,
          62.55662585,
          1.406254414,
          101.7003412,
          13.84973988,
          28.99769315,
          99.04315693,
          15.56135514,
          24.63528393,
          53.98393374,
          42.91449728,
          74.29662112,
          91.17012883,
          49.42440876,
          82.47683519,
          56.15303953,
          37.17063131,
          46.36928662,
          97.02383456,
          40.83182104,
          24.08498313,
          41.14386358,
          21.97388066,
          100.740897,
          61.19971596,
          74.39517002,
          69.04377173,
          56.68718792,
          5.860391715,
          55.72021356,
          79.22021816,
          86.30177517,
          25.26971886,
          36.33294447,
          27.65574228,
          94.79690531,
          58.67366671,
          56.15934471,
          18.40919388,
          86.26936988,
          26.59436195,
          8.452520159,
          56.18131518,
          27.65452669,
          20.87391785,
          77.83354439,
          50.01787825,
          9.290856256,
          75.0284725,
          38.3037698,
          44.70786405,
          22.51016575,
          102.4959452,
          86.76845244,
          13.89748578,
          24.81824269,
          33.94224862,
          92.26970059,
          68.73365081,
          47.38516883,
          32.37576914,
          87.67388681,
          54.57648371,
          18.06450222,
          7.896539841,
          35.00341078,
          36.72823317,
          65.84975426,
          89.59295492,
          61.69026202,
          11.60499315,
          71.0826803,
          43.71901164,
          41.57421008,
          74.25552425,
          66.28310437,
          36.62438077,
          10.32374866,
          7.156457657,
          67.88603132,
          101.1097591,
          98.6132033,
          50.19083844,
          27.83896261,
          55.9249564,
          76.47340872,
          92.05756378,
          27.35245439,
          55.32083476,
          41.39990349,
          93.59057024,
          5.297054029,
          21.01429422,
          2.267059451,
          -0.121860502,
          66.49546208,
          73.83637687,
          42.10140878,
          77.35135732,
          41.02251779,
          14.75305272,
          83.28199022,
          89.93374342,
          2.286571686,
          55.61421297,
          62.15313408,
          89.55803528,
          94.00291863,
          26.78023848,
          -0.764537626,
          0.282866003,
          44.26800515,
          19.85174138,
          47.15960005,
          8.359366572,
          92.08157084,
          41.88734051,
          30.5413129,
          46.87654473,
          96.35659485,
          17.9170699,
          71.67949917,
          32.64997554,
          39.34482965,
          17.03401999,
          52.87524074,
          15.85414849,
          108.8716183,
          49.30477253,
          89.4749477,
          63.67348242,
          83.78410946,
          73.51136922,
          46.80297244,
          5.809946802,
          85.23027975,
          10.58213964,
          21.37698317,
          46.0537745,
          95.2389253,
          94.15149206,
          54.54868046,
          87.36260449,
          88.47741598,
          84.48045678,
          48.79647071,
          10.76675683,
          30.48882921,
          29.76846185,
          13.51574749,
          86.12955884,
          43.30022747,
          51.92110232,
          16.49185287,
          7.998073432,
          97.66689567,
          89.80545367,
          38.07166567,
          60.27852322,
          6.709195759,
          18.35488924,
          56.37058203,
          62.80064204,
          41.25155632,
          19.42637541,
          82.88935804,
          63.61364981,
          11.29627199,
          60.02274882,
          72.60339326,
          11.87964573,
          100.7012737,
          45.12420809,
          14.81106804,
          48.09368034,
          42.29145672,
          52.73389794,
          36.72396986,
          28.64535198,
          62.16675273,
          95.58459518,
          66.04325304,
          99.9566225,
          46.14941984,
          89.13754963,
          69.71787806,
          12.31736648,
          78.20296268,
          71.30995371,
          81.45544709,
          58.59500642,
          94.62509374,
          88.60376995,
          63.64868529,
          94.9752655
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "rgb(36,36,36)"
            },
            "error_y": {
             "color": "rgb(36,36,36)"
            },
            "marker": {
             "line": {
              "color": "rgb(234,234,242)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "rgb(234,234,242)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "baxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "tickcolor": "rgb(36,36,36)",
              "ticklen": 8,
              "ticks": "outside",
              "tickwidth": 2
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "tickcolor": "rgb(36,36,36)",
             "ticklen": 8,
             "ticks": "outside",
             "tickwidth": 2
            },
            "colorscale": [
             [
              0,
              "rgb(2,4,25)"
             ],
             [
              0.06274509803921569,
              "rgb(24,15,41)"
             ],
             [
              0.12549019607843137,
              "rgb(47,23,57)"
             ],
             [
              0.18823529411764706,
              "rgb(71,28,72)"
             ],
             [
              0.25098039215686274,
              "rgb(97,30,82)"
             ],
             [
              0.3137254901960784,
              "rgb(123,30,89)"
             ],
             [
              0.3764705882352941,
              "rgb(150,27,91)"
             ],
             [
              0.4392156862745098,
              "rgb(177,22,88)"
             ],
             [
              0.5019607843137255,
              "rgb(203,26,79)"
             ],
             [
              0.5647058823529412,
              "rgb(223,47,67)"
             ],
             [
              0.6274509803921569,
              "rgb(236,76,61)"
             ],
             [
              0.6901960784313725,
              "rgb(242,107,73)"
             ],
             [
              0.7529411764705882,
              "rgb(244,135,95)"
             ],
             [
              0.8156862745098039,
              "rgb(245,162,122)"
             ],
             [
              0.8784313725490196,
              "rgb(246,188,153)"
             ],
             [
              0.9411764705882353,
              "rgb(247,212,187)"
             ],
             [
              1,
              "rgb(250,234,220)"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "rgb(231,231,240)"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "rgb(183,183,191)"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "rgb(67,103,167)"
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "tickcolor": "rgb(36,36,36)",
            "ticklen": 8,
            "ticks": "outside",
            "tickwidth": 2
           }
          },
          "colorscale": {
           "sequential": [
            [
             0,
             "rgb(2,4,25)"
            ],
            [
             0.06274509803921569,
             "rgb(24,15,41)"
            ],
            [
             0.12549019607843137,
             "rgb(47,23,57)"
            ],
            [
             0.18823529411764706,
             "rgb(71,28,72)"
            ],
            [
             0.25098039215686274,
             "rgb(97,30,82)"
            ],
            [
             0.3137254901960784,
             "rgb(123,30,89)"
            ],
            [
             0.3764705882352941,
             "rgb(150,27,91)"
            ],
            [
             0.4392156862745098,
             "rgb(177,22,88)"
            ],
            [
             0.5019607843137255,
             "rgb(203,26,79)"
            ],
            [
             0.5647058823529412,
             "rgb(223,47,67)"
            ],
            [
             0.6274509803921569,
             "rgb(236,76,61)"
            ],
            [
             0.6901960784313725,
             "rgb(242,107,73)"
            ],
            [
             0.7529411764705882,
             "rgb(244,135,95)"
            ],
            [
             0.8156862745098039,
             "rgb(245,162,122)"
            ],
            [
             0.8784313725490196,
             "rgb(246,188,153)"
            ],
            [
             0.9411764705882353,
             "rgb(247,212,187)"
            ],
            [
             1,
             "rgb(250,234,220)"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "rgb(2,4,25)"
            ],
            [
             0.06274509803921569,
             "rgb(24,15,41)"
            ],
            [
             0.12549019607843137,
             "rgb(47,23,57)"
            ],
            [
             0.18823529411764706,
             "rgb(71,28,72)"
            ],
            [
             0.25098039215686274,
             "rgb(97,30,82)"
            ],
            [
             0.3137254901960784,
             "rgb(123,30,89)"
            ],
            [
             0.3764705882352941,
             "rgb(150,27,91)"
            ],
            [
             0.4392156862745098,
             "rgb(177,22,88)"
            ],
            [
             0.5019607843137255,
             "rgb(203,26,79)"
            ],
            [
             0.5647058823529412,
             "rgb(223,47,67)"
            ],
            [
             0.6274509803921569,
             "rgb(236,76,61)"
            ],
            [
             0.6901960784313725,
             "rgb(242,107,73)"
            ],
            [
             0.7529411764705882,
             "rgb(244,135,95)"
            ],
            [
             0.8156862745098039,
             "rgb(245,162,122)"
            ],
            [
             0.8784313725490196,
             "rgb(246,188,153)"
            ],
            [
             0.9411764705882353,
             "rgb(247,212,187)"
            ],
            [
             1,
             "rgb(250,234,220)"
            ]
           ]
          },
          "colorway": [
           "rgb(76,114,176)",
           "rgb(221,132,82)",
           "rgb(85,168,104)",
           "rgb(196,78,82)",
           "rgb(129,114,179)",
           "rgb(147,120,96)",
           "rgb(218,139,195)",
           "rgb(140,140,140)",
           "rgb(204,185,116)",
           "rgb(100,181,205)"
          ],
          "font": {
           "color": "rgb(36,36,36)"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "rgb(234,234,242)",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "paper_bgcolor": "white",
          "plot_bgcolor": "rgb(234,234,242)",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           },
           "bgcolor": "rgb(234,234,242)",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "rgb(234,234,242)",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "showgrid": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "rgb(234,234,242)",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "showgrid": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "rgb(234,234,242)",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "showgrid": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "fillcolor": "rgb(67,103,167)",
           "line": {
            "width": 0
           },
           "opacity": 0.5
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           },
           "bgcolor": "rgb(234,234,242)",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "showgrid": true,
            "ticks": ""
           }
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "showgrid": true,
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white"
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "showgrid": true,
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white"
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "x"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "y"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "px.scatter(x=train_data['x'], y=train_data['y'],template='seaborn')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c04370",
   "metadata": {
    "papermill": {
     "duration": 0.006158,
     "end_time": "2023-09-29T06:12:58.944342",
     "exception": false,
     "start_time": "2023-09-29T06:12:58.938184",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**The data appears to be well-suited for a Linear model, such as LinearRegression.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b767a9",
   "metadata": {
    "papermill": {
     "duration": 0.005931,
     "end_time": "2023-09-29T06:12:58.956711",
     "exception": false,
     "start_time": "2023-09-29T06:12:58.950780",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id=\"4\"></a>\n",
    "<h1 style='background:#00EFFF;border:0; color:black;\n",
    "    box-shadow: 10px 10px 5px 0px rgba(0,0,0,0.75);\n",
    "    transform: rotateX(10deg);\n",
    "    '><center style='color: #000000;'>Data Preprocessing</center></h1>\n",
    "\n",
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cfe1509",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-29T06:12:58.971889Z",
     "iopub.status.busy": "2023-09-29T06:12:58.971394Z",
     "iopub.status.idle": "2023-09-29T06:12:58.977633Z",
     "shell.execute_reply": "2023-09-29T06:12:58.976503Z"
    },
    "papermill": {
     "duration": 0.016752,
     "end_time": "2023-09-29T06:12:58.979968",
     "exception": false,
     "start_time": "2023-09-29T06:12:58.963216",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set training data and target\n",
    "X_train = train_data['x'].values\n",
    "y_train = train_data['y'].values\n",
    "\n",
    "# Set testing data and target\n",
    "X_test = test_data['x'].values\n",
    "y_test = test_data['y'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a0e356",
   "metadata": {
    "papermill": {
     "duration": 0.007414,
     "end_time": "2023-09-29T06:12:58.993854",
     "exception": false,
     "start_time": "2023-09-29T06:12:58.986440",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Standardize the data\n",
    "\n",
    "Standardization is a preprocessing technique used in machine learning to rescale and transform the features (variables) of a dataset to have a mean of 0 and a standard deviation of 1. It is also known as \"z-score normalization\" or \"z-score scaling.\" Standardization is an essential step in the data preprocessing pipeline for various reasons:\n",
    "\n",
    "### Why Use Standardization in Machine Learning?\n",
    "\n",
    "1. **Mean Centering**: Standardization centers the data by subtracting the mean from each feature. This ensures that the transformed data has a mean of 0. Mean centering is crucial because it helps in capturing the relative variations in the data.\n",
    "\n",
    "2. **Scale Invariance**: Standardization scales the data by dividing each feature by its standard deviation. This makes the data scale-invariant, meaning that the scale of the features no longer affects the performance of many machine learning algorithms. Without standardization, features with larger scales may dominate the learning process.\n",
    "\n",
    "3. **Improved Convergence**: Many machine learning algorithms, such as gradient-based optimization algorithms (e.g., gradient descent), converge faster when the features are standardized. It reduces the potential for numerical instability and overflow/underflow issues during training.\n",
    "\n",
    "4. **Comparability**: Standardizing the features makes it easier to compare and interpret the importance of each feature. This is especially important in models like linear regression, where the coefficients represent the feature's impact on the target variable.\n",
    "\n",
    "5. **Regularization**: In regularization techniques like Ridge and Lasso regression, the regularization strength is applied uniformly to all features. Standardization ensures that the regularization term applies fairly to all features.\n",
    "\n",
    "### How to Standardize Data\n",
    "\n",
    "The standardization process involves the following steps:\n",
    "\n",
    "1. Calculate the mean ($\\mu$) and standard deviation ($\\sigma$) for each feature in the dataset.\n",
    "2. For each data point (sample), subtract the mean ($\\mu$) of the feature and then divide by the standard deviation ($\\sigma$) of the feature.\n",
    "\n",
    "Mathematically, the standardized value for a feature `x` in a dataset is calculated as:\n",
    "\n",
    "$$\n",
    "\\text{Standardized value} = \\frac{x - \\mu}{\\sigma}\n",
    "$$\n",
    "\n",
    "Here, `x` is the original value of the feature, $\\mu$ is the mean of the feature, and $\\sigma$ is the standard deviation of the feature.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65d33064",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-29T06:12:59.009631Z",
     "iopub.status.busy": "2023-09-29T06:12:59.009141Z",
     "iopub.status.idle": "2023-09-29T06:12:59.016356Z",
     "shell.execute_reply": "2023-09-29T06:12:59.015379Z"
    },
    "papermill": {
     "duration": 0.01774,
     "end_time": "2023-09-29T06:12:59.018509",
     "exception": false,
     "start_time": "2023-09-29T06:12:59.000769",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def standardize_data(X_train, X_test):\n",
    "    \"\"\"\n",
    "    Standardizes the input data using mean and standard deviation.\n",
    "\n",
    "    Parameters:\n",
    "        X_train (numpy.ndarray): Training data.\n",
    "        X_test (numpy.ndarray): Testing data.\n",
    "\n",
    "    Returns:\n",
    "        Tuple of standardized training and testing data.\n",
    "    \"\"\"\n",
    "    # Calculate the mean and standard deviation using the training data\n",
    "    mean = np.mean(X_train, axis=0)\n",
    "    std = np.std(X_train, axis=0)\n",
    "    \n",
    "    # Standardize the data\n",
    "    X_train = (X_train - mean) / std\n",
    "    X_test = (X_test - mean) / std\n",
    "    \n",
    "    return X_train, X_test\n",
    "\n",
    "X_train, X_test = standardize_data(X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca5df04",
   "metadata": {
    "papermill": {
     "duration": 0.005857,
     "end_time": "2023-09-29T06:12:59.032384",
     "exception": false,
     "start_time": "2023-09-29T06:12:59.026527",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Reshaping data for the correct shape for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "647e82d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-29T06:12:59.047808Z",
     "iopub.status.busy": "2023-09-29T06:12:59.046985Z",
     "iopub.status.idle": "2023-09-29T06:12:59.052231Z",
     "shell.execute_reply": "2023-09-29T06:12:59.051335Z"
    },
    "papermill": {
     "duration": 0.015738,
     "end_time": "2023-09-29T06:12:59.054487",
     "exception": false,
     "start_time": "2023-09-29T06:12:59.038749",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = np.expand_dims(X_train, axis=-1)\n",
    "X_test = np.expand_dims(X_test, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0601c0",
   "metadata": {
    "papermill": {
     "duration": 0.006182,
     "end_time": "2023-09-29T06:12:59.067302",
     "exception": false,
     "start_time": "2023-09-29T06:12:59.061120",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id=\"5\"></a>\n",
    "<h1 style='background:#00EFFF;border:0; color:black;\n",
    "    box-shadow: 10px 10px 5px 0px rgba(0,0,0,0.75);\n",
    "    transform: rotateX(10deg);\n",
    "    '><center style='color: #000000;'>Model Implementation</center></h1>\n",
    "\n",
    "# Model Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858b89ec",
   "metadata": {
    "papermill": {
     "duration": 0.006194,
     "end_time": "2023-09-29T06:12:59.079878",
     "exception": false,
     "start_time": "2023-09-29T06:12:59.073684",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Linear Regression Model\n",
    "\n",
    "Linear regression is a fundamental model in machine learning used for predicting a continuous output variable based on input features. The model function for linear regression is represented as:\n",
    "\n",
    "$$f_{w,b}(x) = wx + b$$\n",
    "\n",
    "In this equation, $f_{w,b}(x)$ represents the predicted output, $w$ is the weight parameter, $b$ is the bias parameter, and $x$ is the input feature.\n",
    "\n",
    "## Model Training\n",
    "\n",
    "To train a linear regression model, we aim to find the best values for the parameters $(w, b)$ that best fit our dataset.\n",
    "\n",
    "### Forward Pass\n",
    "\n",
    "The forward pass is a step where we compute the linear regression output for the input data $X$ using the current weights and biases. It's essentially applying our model to the input data.\n",
    "\n",
    "### Cost Function\n",
    "\n",
    "The cost function is used to measure how well our model is performing. It quantifies the difference between the predicted values and the actual values in our dataset. The cost function is defined as:\n",
    "\n",
    "$$J(w,b) = \\frac{1}{2m} \\sum_{i=1}^{m}(f_{w,b}(x^{(i)}) - y^{(i)})^2$$\n",
    "\n",
    "Here, $J(w, b)$ is the cost, $m$ is the number of training examples, $x^{(i)}$ is the input data for the $i$-th example, $y^{(i)}$ is the actual output for the $i$-th example, and $w$ and $b$ are the weight and bias parameters, respectively.\n",
    "\n",
    "### Backward Pass (Gradient Computation)\n",
    "\n",
    "The backward pass computes the gradients of the cost function with respect to the weights and biases. These gradients are crucial for updating the model parameters during training. The gradient formulas are as follows:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial J(w,b)}{\\partial b} = \\frac{1}{m} \\sum_{i=0}^{m-1} (f_{w,b}(X^{(i)}) - y^{(i)})\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial J(w,b)}{\\partial w} = \\frac{1}{m} \\sum_{i=0}^{m-1} (f_{w,b}(X^{(i)}) - y^{(i)})X^{(i)}\n",
    "$$\n",
    "\n",
    "## Training Process\n",
    "\n",
    "The training process involves iteratively updating the weights and biases to minimize the cost function. This is typically done through an optimization algorithm like gradient descent. The update equations for parameters are:\n",
    "\n",
    "$$w \\leftarrow w - \\alpha \\frac{\\partial J}{\\partial w}$$\n",
    "\n",
    "$$b \\leftarrow b - \\alpha \\frac{\\partial J}{\\partial b}$$\n",
    "\n",
    "Here, $\\alpha$ represents the learning rate, which controls the step size during parameter updates.\n",
    "\n",
    "By iteratively performing the forward pass, computing the cost, performing the backward pass, and updating the parameters, the model learns to make better predictions and fit the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb292d3c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfc74ecb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-29T06:12:59.095795Z",
     "iopub.status.busy": "2023-09-29T06:12:59.094892Z",
     "iopub.status.idle": "2023-09-29T06:12:59.115882Z",
     "shell.execute_reply": "2023-09-29T06:12:59.114721Z"
    },
    "papermill": {
     "duration": 0.032422,
     "end_time": "2023-09-29T06:12:59.118771",
     "exception": false,
     "start_time": "2023-09-29T06:12:59.086349",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "    \"\"\"\n",
    "    Linear Regression Model with Gradient Descent\n",
    "\n",
    "    Linear regression is a supervised machine learning algorithm used for modeling the relationship\n",
    "    between a dependent variable (target) and one or more independent variables (features) by fitting\n",
    "    a linear equation to the observed data.\n",
    "\n",
    "    This class implements a linear regression model using gradient descent optimization for training.\n",
    "    It provides methods for model initialization, training, prediction, and model persistence.\n",
    "\n",
    "    Parameters:\n",
    "        learning_rate (float): The learning rate used in gradient descent.\n",
    "        convergence_tol (float, optional): The tolerance for convergence (stopping criterion). Defaults to 1e-6.\n",
    "\n",
    "    Attributes:\n",
    "        W (numpy.ndarray): Coefficients (weights) for the linear regression model.\n",
    "        b (float): Intercept (bias) for the linear regression model.\n",
    "\n",
    "    Methods:\n",
    "        initialize_parameters(n_features): Initialize model parameters.\n",
    "        forward(X): Compute the forward pass of the linear regression model.\n",
    "        compute_cost(predictions): Compute the mean squared error cost.\n",
    "        backward(predictions): Compute gradients for model parameters.\n",
    "        fit(X, y, iterations, plot_cost=True): Fit the linear regression model to training data.\n",
    "        predict(X): Predict target values for new input data.\n",
    "        save_model(filename=None): Save the trained model to a file using pickle.\n",
    "        load_model(filename): Load a trained model from a file using pickle.\n",
    "\n",
    "    Examples:\n",
    "        >>> from linear_regression import LinearRegression\n",
    "        >>> model = LinearRegression(learning_rate=0.01)\n",
    "        >>> model.fit(X_train, y_train, iterations=1000)\n",
    "        >>> predictions = model.predict(X_test)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, learning_rate, convergence_tol=1e-6):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.convergence_tol = convergence_tol\n",
    "        self.W = None\n",
    "        self.b = None\n",
    "\n",
    "    def initialize_parameters(self, n_features):\n",
    "        \"\"\"\n",
    "        Initialize model parameters.\n",
    "\n",
    "        Parameters:\n",
    "            n_features (int): The number of features in the input data.\n",
    "        \"\"\"\n",
    "        self.W = np.random.randn(n_features) * 0.01\n",
    "        self.b = 0\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        Compute the forward pass of the linear regression model.\n",
    "\n",
    "        Parameters:\n",
    "            X (numpy.ndarray): Input data of shape (m, n_features).\n",
    "\n",
    "        Returns:\n",
    "            numpy.ndarray: Predictions of shape (m,).\n",
    "        \"\"\"\n",
    "        return np.dot(X, self.W) + self.b\n",
    "\n",
    "    def compute_cost(self, predictions):\n",
    "        \"\"\"\n",
    "        Compute the mean squared error cost.\n",
    "\n",
    "        Parameters:\n",
    "            predictions (numpy.ndarray): Predictions of shape (m,).\n",
    "\n",
    "        Returns:\n",
    "            float: Mean squared error cost.\n",
    "        \"\"\"\n",
    "        m = len(predictions)\n",
    "        cost = np.sum(np.square(predictions - self.y)) / (2 * m)\n",
    "        return cost\n",
    "\n",
    "    def backward(self, predictions):\n",
    "        \"\"\"\n",
    "        Compute gradients for model parameters.\n",
    "\n",
    "        Parameters:\n",
    "            predictions (numpy.ndarray): Predictions of shape (m,).\n",
    "\n",
    "        Updates:\n",
    "            numpy.ndarray: Gradient of W.\n",
    "            float: Gradient of b.\n",
    "        \"\"\"\n",
    "        m = len(predictions)\n",
    "        self.dW = np.dot(predictions - self.y, self.X) / m\n",
    "        self.db = np.sum(predictions - self.y) / m\n",
    "\n",
    "    def fit(self, X, y, iterations, plot_cost=True):\n",
    "        \"\"\"\n",
    "        Fit the linear regression model to the training data.\n",
    "\n",
    "        Parameters:\n",
    "            X (numpy.ndarray): Training input data of shape (m, n_features).\n",
    "            y (numpy.ndarray): Training labels of shape (m,).\n",
    "            iterations (int): The number of iterations for gradient descent.\n",
    "            plot_cost (bool, optional): Whether to plot the cost during training. Defaults to True.\n",
    "\n",
    "        Raises:\n",
    "            AssertionError: If input data and labels are not NumPy arrays or have mismatched shapes.\n",
    "\n",
    "        Plots:\n",
    "            Plotly line chart showing cost vs. iteration (if plot_cost is True).\n",
    "        \"\"\"\n",
    "        assert isinstance(X, np.ndarray), \"X must be a NumPy array\"\n",
    "        assert isinstance(y, np.ndarray), \"y must be a NumPy array\"\n",
    "        assert X.shape[0] == y.shape[0], \"X and y must have the same number of samples\"\n",
    "        assert iterations > 0, \"Iterations must be greater than 0\"\n",
    "\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.initialize_parameters(X.shape[1])\n",
    "        costs = []\n",
    "\n",
    "        for i in range(iterations):\n",
    "            predictions = self.forward(X)\n",
    "            cost = self.compute_cost(predictions)\n",
    "            self.backward(predictions)\n",
    "            self.W -= self.learning_rate * self.dW\n",
    "            self.b -= self.learning_rate * self.db\n",
    "            costs.append(cost)\n",
    "\n",
    "            if i % 100 == 0:\n",
    "                print(f'Iteration: {i}, Cost: {cost}')\n",
    "\n",
    "            if i > 0 and abs(costs[-1] - costs[-2]) < self.convergence_tol:\n",
    "                print(f'Converged after {i} iterations.')\n",
    "                break\n",
    "\n",
    "        if plot_cost:\n",
    "            fig = px.line(y=costs, title=\"Cost vs Iteration\", template=\"plotly_dark\")\n",
    "            fig.update_layout(\n",
    "                title_font_color=\"#41BEE9\",\n",
    "                xaxis=dict(color=\"#41BEE9\", title=\"Iterations\"),\n",
    "                yaxis=dict(color=\"#41BEE9\", title=\"Cost\")\n",
    "            )\n",
    "\n",
    "            fig.show()\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict target values for new input data.\n",
    "\n",
    "        Parameters:\n",
    "            X (numpy.ndarray): Input data of shape (m, n_features).\n",
    "\n",
    "        Returns:\n",
    "            numpy.ndarray: Predicted target values of shape (m,).\n",
    "        \"\"\"\n",
    "        return self.forward(X)\n",
    "    \n",
    "\n",
    "    def save_model(self, filename=None):\n",
    "        \"\"\"\n",
    "        Save the trained model to a file using pickle.\n",
    "\n",
    "        Parameters:\n",
    "            filename (str): The name of the file to save the model to.\n",
    "        \"\"\"\n",
    "        model_data = {\n",
    "            'learning_rate': self.learning_rate,\n",
    "            'convergence_tol': self.convergence_tol,\n",
    "            'W': self.W,\n",
    "            'b': self.b\n",
    "        }\n",
    "\n",
    "        with open(filename, 'wb') as file:\n",
    "            pickle.dump(model_data, file)\n",
    "\n",
    "    @classmethod\n",
    "    def load_model(cls, filename):\n",
    "        \"\"\"\n",
    "        Load a trained model from a file using pickle.\n",
    "\n",
    "        Parameters:\n",
    "            filename (str): The name of the file to load the model from.\n",
    "\n",
    "        Returns:\n",
    "            LinearRegression: An instance of the LinearRegression class with loaded parameters.\n",
    "        \"\"\"\n",
    "        with open(filename, 'rb') as file:\n",
    "            model_data = pickle.load(file)\n",
    "\n",
    "        # Create a new instance of the class and initialize it with the loaded parameters\n",
    "        loaded_model = cls(model_data['learning_rate'], model_data['convergence_tol'])\n",
    "        loaded_model.W = model_data['W']\n",
    "        loaded_model.b = model_data['b']\n",
    "\n",
    "        return loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83a805ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-29T06:12:59.135445Z",
     "iopub.status.busy": "2023-09-29T06:12:59.134598Z",
     "iopub.status.idle": "2023-09-29T06:12:59.284274Z",
     "shell.execute_reply": "2023-09-29T06:12:59.282674Z"
    },
    "papermill": {
     "duration": 0.161243,
     "end_time": "2023-09-29T06:12:59.287070",
     "exception": false,
     "start_time": "2023-09-29T06:12:59.125827",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0, Cost: 1669.9140574702328\n",
      "Iteration: 100, Cost: 227.14135935079779\n",
      "Iteration: 200, Cost: 33.83914236281146\n",
      "Iteration: 300, Cost: 7.940574181437842\n",
      "Iteration: 400, Cost: 4.470692437210656\n",
      "Iteration: 500, Cost: 4.005798809323515\n",
      "Iteration: 600, Cost: 3.943512512215656\n",
      "Iteration: 700, Cost: 3.93516741438104\n",
      "Iteration: 800, Cost: 3.9340493408865003\n",
      "Converged after 863 iterations.\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "x=%{x}<br>y=%{y}<extra></extra>",
         "legendgroup": "",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499,
          500,
          501,
          502,
          503,
          504,
          505,
          506,
          507,
          508,
          509,
          510,
          511,
          512,
          513,
          514,
          515,
          516,
          517,
          518,
          519,
          520,
          521,
          522,
          523,
          524,
          525,
          526,
          527,
          528,
          529,
          530,
          531,
          532,
          533,
          534,
          535,
          536,
          537,
          538,
          539,
          540,
          541,
          542,
          543,
          544,
          545,
          546,
          547,
          548,
          549,
          550,
          551,
          552,
          553,
          554,
          555,
          556,
          557,
          558,
          559,
          560,
          561,
          562,
          563,
          564,
          565,
          566,
          567,
          568,
          569,
          570,
          571,
          572,
          573,
          574,
          575,
          576,
          577,
          578,
          579,
          580,
          581,
          582,
          583,
          584,
          585,
          586,
          587,
          588,
          589,
          590,
          591,
          592,
          593,
          594,
          595,
          596,
          597,
          598,
          599,
          600,
          601,
          602,
          603,
          604,
          605,
          606,
          607,
          608,
          609,
          610,
          611,
          612,
          613,
          614,
          615,
          616,
          617,
          618,
          619,
          620,
          621,
          622,
          623,
          624,
          625,
          626,
          627,
          628,
          629,
          630,
          631,
          632,
          633,
          634,
          635,
          636,
          637,
          638,
          639,
          640,
          641,
          642,
          643,
          644,
          645,
          646,
          647,
          648,
          649,
          650,
          651,
          652,
          653,
          654,
          655,
          656,
          657,
          658,
          659,
          660,
          661,
          662,
          663,
          664,
          665,
          666,
          667,
          668,
          669,
          670,
          671,
          672,
          673,
          674,
          675,
          676,
          677,
          678,
          679,
          680,
          681,
          682,
          683,
          684,
          685,
          686,
          687,
          688,
          689,
          690,
          691,
          692,
          693,
          694,
          695,
          696,
          697,
          698,
          699,
          700,
          701,
          702,
          703,
          704,
          705,
          706,
          707,
          708,
          709,
          710,
          711,
          712,
          713,
          714,
          715,
          716,
          717,
          718,
          719,
          720,
          721,
          722,
          723,
          724,
          725,
          726,
          727,
          728,
          729,
          730,
          731,
          732,
          733,
          734,
          735,
          736,
          737,
          738,
          739,
          740,
          741,
          742,
          743,
          744,
          745,
          746,
          747,
          748,
          749,
          750,
          751,
          752,
          753,
          754,
          755,
          756,
          757,
          758,
          759,
          760,
          761,
          762,
          763,
          764,
          765,
          766,
          767,
          768,
          769,
          770,
          771,
          772,
          773,
          774,
          775,
          776,
          777,
          778,
          779,
          780,
          781,
          782,
          783,
          784,
          785,
          786,
          787,
          788,
          789,
          790,
          791,
          792,
          793,
          794,
          795,
          796,
          797,
          798,
          799,
          800,
          801,
          802,
          803,
          804,
          805,
          806,
          807,
          808,
          809,
          810,
          811,
          812,
          813,
          814,
          815,
          816,
          817,
          818,
          819,
          820,
          821,
          822,
          823,
          824,
          825,
          826,
          827,
          828,
          829,
          830,
          831,
          832,
          833,
          834,
          835,
          836,
          837,
          838,
          839,
          840,
          841,
          842,
          843,
          844,
          845,
          846,
          847,
          848,
          849,
          850,
          851,
          852,
          853,
          854,
          855,
          856,
          857,
          858,
          859,
          860,
          861,
          862,
          863
         ],
         "xaxis": "x",
         "y": [
          1669.9140574702328,
          1636.7610518662732,
          1604.2677910738325,
          1572.4211461711616,
          1541.2082495020536,
          1510.616489476661,
          1480.6335054757737,
          1451.247182856504,
          1422.4456480573576,
          1394.2172638007144,
          1366.5506243907787,
          1339.4345511051004,
          1312.858087677807,
          1286.8104958727167,
          1261.281251144548,
          1236.2600383864694,
          1211.736747762277,
          1187.701470621506,
          1164.1444954958363,
          1141.0563041751673,
          1118.4275678617796,
          1096.2491434010283,
          1074.512069587046,
          1053.207563541962,
          1032.327017167175,
          1011.8619936652467,
          991.8042241310063,
          972.1456042104977,
          952.8781908264068,
          933.9941989686595,
          915.4859985488814,
          897.346111317457,
          879.5672078419377,
          862.1421045455812,
          845.0637608048226,
          828.3252761045048,
          811.9198872497234,
          795.840965633152,
          780.0820145567506,
          764.6366666067695,
          749.4986810809929,
          734.6619414671794,
          720.1204529716806,
          705.8683400972425,
          691.8998442690056,
          678.2093215077506,
          664.7912401494445,
          651.6401786101687,
          638.7508231955246,
          626.1179659536319,
          613.7365025708528,
          601.6014303093912,
          589.7078459859324,
          578.0509439905105,
          566.6260143447975,
          555.4284407990343,
          544.4536989668317,
          533.6973544970899,
          523.1550612822961,
          512.8225597024766,
          502.69567490409554,
          492.7703151132022,
          483.0424699821477,
          473.50820896920106,
          464.1636797504123,
          455.00510666307724,
          446.02878918018007,
          437.2311004151927,
          428.60848565662866,
          420.1574609317599,
          411.8746115989161,
          403.75659096779583,
          395.8001189472349,
          388.00198071988314,
          380.35902544325563,
          372.86816497663307,
          365.52637263329626,
          358.3306819575919,
          351.278185526334,
          344.36603377405817,
          337.5914338416526,
          330.9516484479019,
          324.44399478348686,
          318.0658434269937,
          311.8146172824948,
          305.68779053827126,
          299.6828876462579,
          293.7974823217956,
          288.02919656329004,
          282.3756996913788,
          276.8347074072186,
          271.4039808695131,
          266.08132578990796,
          260.864591546387,
          255.75167031431207,
          250.7404962147555,
          245.82904447978004,
          241.0153306343306,
          236.29740969440567,
          231.6733753811852,
          227.14135935079779,
          222.69953043941504,
          218.346093923369,
          214.0792907939922,
          209.89739704689,
          205.79872298535497,
          201.78161253764463,
          197.84444258784373,
          193.9856223200438,
          190.2035925755731,
          186.4968252230174,
          182.8638225407776,
          179.30311661191433,
          175.8132687310355,
          172.39286882298606,
          169.0405348731068,
          165.7549123688302,
          162.53467375238858,
          159.37851788441432,
          156.28516951821268,
          153.2533787844984,
          150.2819206863852,
          147.3695946044243,
          144.51522381149448,
          141.71765499734397,
          138.97575780259504,
          136.28842436202157,
          133.65456885691557,
          131.07312707636112,
          128.54305598723977,
          126.06333331279193,
          123.63295711956555,
          121.25094541258441,
          118.9163357385722,
          116.62818479707278,
          114.38556805930924,
          112.18757939462716,
          110.03333070437232,
          107.92195156305353,
          105.852588866647,
          103.82440648789888,
          101.83658493848792,
          99.88832103791016,
          97.97882758895393,
          96.10733305963198,
          94.2730812714435,
          92.47533109384,
          90.71335614477081,
          88.98644449718806,
          87.29389839139223,
          85.6350339531017,
          84.00918091713315,
          82.41568235658042,
          80.85389441738265,
          79.32318605817493,
          77.82293879531544,
          76.35254645298681,
          74.9114149182706,
          73.49896190109523,
          72.11461669896164,
          70.75781996635054,
          69.4280234887184,
          68.12468996099113,
          66.84729277046564,
          65.59531578403158,
          64.36825313962754,
          63.16560904184717,
          61.98689756161264,
          60.831642439834766,
          59.69937689498025,
          58.589643434468336,
          57.50199366982059,
          56.43598813548933,
          55.391196111291315,
          54.367195448374844,
          53.363572398650405,
          52.37992144761549,
          51.41584515050616,
          50.470953971709235,
          49.54486612737042,
          48.63720743113392,
          47.747611142952586,
          46.87571782090602,
          46.02117517596819,
          45.1836379296646,
          44.362767674562484,
          43.55823273753692,
          42.76970804575811,
          41.99687499534571,
          41.239421322636545,
          40.497040978014255,
          39.76943400224998,
          39.0563064053034,
          38.35737004753605,
          37.672342523288286,
          37.00094704677308,
          36.34291234024051,
          35.69797252436793,
          35.065867010831205,
          34.44634039701384,
          33.83914236281146,
          33.24402756948974,
          32.6607555605551,
          32.08909066459826,
          31.528801900070953,
          30.97966288195772,
          30.44145173030497,
          29.91395098057009,
          29.396947495754937,
          28.890232380287635,
          28.39360089561809,
          27.906852377493486,
          27.429790154879573,
          26.962221470495667,
          26.503957402931007,
          26.05481279031086,
          25.614606155481887,
          25.18315963268599,
          24.760298895693726,
          24.345853087367612,
          23.939654750627184,
          23.541539760787888,
          23.151347259246393,
          22.768919588485605,
          22.39410222837293,
          22.026743733726498,
          21.666695673123545,
          21.313812568926604,
          20.96795183850318,
          20.628973736615176,
          20.296741298954736,
          19.97112028680374,
          19.65197913279454,
          19.339188887750115,
          19.032623168582088,
          18.732158107225516,
          18.437672300589934,
          18.149046761506412,
          17.866164870650618,
          17.588912329422893,
          17.317177113765588,
          17.050849428899838,
          16.78982166496294,
          16.53398835352836,
          16.283246124991354,
          16.03749366680221,
          15.796631682531062,
          15.56056285174689,
          15.329191790695324,
          15.102425013758694,
          14.88017089568309,
          14.662339634557206,
          14.448843215527717,
          14.239595375236924,
          14.03451156696791,
          13.83350892648344,
          13.636506238544634,
          13.443423904095813,
          13.254183908102506,
          13.068709788029478,
          12.8869266029459,
          12.708760903245487,
          12.5341407009691,
          12.362995440718016,
          12.195255971145933,
          12.030854517018344,
          11.869724651827884,
          11.711801270954703,
          11.557020565360911,
          11.405319995808426,
          11.256638267590029,
          11.110915305763188,
          10.968092230876707,
          10.82811133518045,
          10.690916059308556,
          10.556450969426521,
          10.424661734833148,
          10.29549510600817,
          10.168898893096818,
          10.044821944822385,
          9.923214127818625,
          9.804026306373247,
          9.687210322574616,
          9.572718976853581,
          9.4605060089124,
          9.350526079033237,
          9.242734749758677,
          9.13708846793668,
          9.03354454712295,
          8.9320611503334,
          8.832597273139982,
          8.735112727102699,
          8.639568123531562,
          8.545924857571485,
          8.454145092604008,
          8.364191744959385,
          8.276028468932896,
          8.189619642099332,
          8.104930350919759,
          8.021926376634662,
          7.940574181437842,
          7.860840894925437,
          7.782694300814632,
          7.706102823926629,
          7.6310355174286935,
          7.55746205033006,
          7.485352695226695,
          7.414678316289888,
          7.345410357493925,
          7.277520831077992,
          7.210982306237736,
          7.14576789804181,
          7.08185125656898,
          7.0192065562614605,
          6.95780848549006,
          6.89763223632701,
          6.838653494522312,
          6.780848429679518,
          6.724193685627102,
          6.668666370981325,
          6.614244049896993,
          6.560904733002247,
          6.508626868513703,
          6.457389333528486,
          6.407171425489471,
          6.357952853820431,
          6.309713731727609,
          6.262434568164426,
          6.216096259956161,
          6.170680084081231,
          6.126167690106219,
          6.082541092771306,
          6.0397826647233614,
          5.997875129393572,
          5.956801554016837,
          5.916545342790109,
          5.877090230166785,
          5.838420274284671,
          5.800519850524613,
          5.763373645197378,
          5.726966649356149,
          5.691284152732159,
          5.656311737790995,
          5.622035273907156,
          5.588440911654607,
          5.55551507721088,
          5.523244466872591,
          5.491616041680027,
          5.460617022148791,
          5.430234883106228,
          5.4004573486306136,
          5.371272387091068,
          5.342668206286158,
          5.314633248679268,
          5.28715618672875,
          5.260225918311048,
          5.233831562234858,
          5.207962453844585,
          5.1826081407112845,
          5.1577583784093335,
          5.133403126377195,
          5.109532543860486,
          5.086136985935869,
          5.063206999613949,
          5.040733320019833,
          5.018706866649642,
          4.997118739701517,
          4.975960216479658,
          4.9552227478699145,
          4.9348979548855025,
          4.914977625281483,
          4.895453710236588,
          4.876318321101076,
          4.8575637262093725,
          4.839182347756002,
          4.821166758733856,
          4.803509679933256,
          4.786203977000789,
          4.7692426575566795,
          4.752618868369504,
          4.736325892587155,
          4.720357147022874,
          4.704706179495317,
          4.689366666221563,
          4.6743324092619565,
          4.6595973340158485,
          4.6451554867671385,
          4.631001032278673,
          4.617128251434529,
          4.603531538929186,
          4.590205401002699,
          4.577144453220946,
          4.5643434183000515,
          4.551797123974086,
          4.539500500905204,
          4.527448580635396,
          4.515636493578956,
          4.504059467054938,
          4.492712823358746,
          4.4815919778721085,
          4.470692437210656,
          4.460009797408368,
          4.449539742138144,
          4.439278040967795,
          4.429220547650736,
          4.419363198450688,
          4.4097020104997195,
          4.400233080188976,
          4.390952581591417,
          4.381856764915948,
          4.372941954992323,
          4.364204549786179,
          4.355641018943636,
          4.34724790236486,
          4.339021808806003,
          4.330959414508965,
          4.323057461858436,
          4.315312758065655,
          4.307722173878353,
          4.300282642316372,
          4.292991157432479,
          4.285844773097775,
          4.278840601811335,
          4.27197581353349,
          4.265247634542378,
          4.258653346313188,
          4.252190284419759,
          4.245855837458009,
          4.239647445990794,
          4.233562601513781,
          4.227598845441862,
          4.22175376811577,
          4.216025007828468,
          4.210410249870881,
          4.204907225596654,
          4.1995137115054835,
          4.194227528344728,
          4.189046540228871,
          4.183968653776519,
          4.178991817264568,
          4.174114019799205,
          4.169333290503405,
          4.164647697720588,
          4.1600553482341525,
          4.155554386502497,
          4.151142993909299,
          4.146819388028707,
          4.142581821905136,
          4.138428583347426,
          4.134357994237014,
          4.130368409849901,
          4.1264582181920915,
          4.1226258393482675,
          4.118869724843441,
          4.115188357017259,
          4.111580248410819,
          4.108043941165645,
          4.104578006434651,
          4.101181043804804,
          4.097851680731291,
          4.09458857198294,
          4.091390399098682,
          4.0882558698548195,
          4.085183717742912,
          4.082172701458031,
          4.079221604397218,
          4.0763292341679165,
          4.073494422106179,
          4.070716022804467,
          4.067992913648859,
          4.0653239943654516,
          4.062708186575782,
          4.060144433361126,
          4.057631698835442,
          4.05516896772682,
          4.05275524496726,
          4.050389555290612,
          4.048070942838531,
          4.045798470774247,
          4.04357122090404,
          4.041388293306253,
          4.0392488059676595,
          4.0371518944271045,
          4.035096711426208,
          4.03308242656703,
          4.03110822597655,
          4.029173311977821,
          4.027276902767664,
          4.025418232100789,
          4.023596548980187,
          4.0218111173536855,
          4.020061215816549,
          4.018346137320003,
          4.016665188885537,
          4.015017691324916,
          4.013402978965754,
          4.011820399382537,
          4.010269313133025,
          4.008749093499883,
          4.007259126237437,
          4.005798809323515,
          4.004367552716179,
          4.00296477811533,
          4.001589918729037,
          4.000242419044531,
          3.998921734603747,
          3.9976273317833355,
          3.9963586875790496,
          3.9951152893944286,
          3.993896634833683,
          3.9927022314986944,
          3.991531596790074,
          3.990384257712152,
          3.989259750681884,
          3.988157621341516,
          3.987077424375022,
          3.986018723328161,
          3.984981090432134,
          3.983964106430737,
          3.9829673604109668,
          3.981990449636991,
          3.9810329793874164,
          3.9800945627958093,
          3.9791748206943747,
          3.978273381460758,
          3.9773898808678925,
          3.9765239619368242,
          3.9756752747924824,
          3.9748434765223166,
          3.974028231037724,
          3.973229208938276,
          3.9724460873786076,
          3.971678549937975,
          3.97092628649241,
          3.970188993089414,
          3.969466371825137,
          3.96875813072402,
          3.9680639836208154,
          3.967383650044963,
          3.9667168551072693,
          3.9660633293888377,
          3.9654228088322028,
          3.964795034634644,
          3.964179753143618,
          3.96357671575426,
          3.962985678808954,
          3.9624064034988593,
          3.961838655767434,
          3.961282206215863,
          3.9607368300103696,
          3.960202306791367,
          3.959678420584421,
          3.959164959712994,
          3.9586617167129075,
          3.9581684882485235,
          3.95768507503058,
          3.9572112817356744,
          3.956746916927337,
          3.9562917929786847,
          3.955845725996611,
          3.9554085357474817,
          3.9549800455843087,
          3.9545600823753837,
          3.9541484764343156,
          3.953745061451476,
          3.953349674426794,
          3.9529621556039025,
          3.952582348405588,
          3.9522100993705194,
          3.9518452580912484,
          3.951487677153435,
          3.951137212076283,
          3.950793721254168,
          3.9504570658994127,
          3.9501271099862163,
          3.949803720195695,
          3.949486765862002,
          3.94917611891955,
          3.948871653851253,
          3.9485732476378157,
          3.948280779708027,
          3.947994131890039,
          3.9477131883636294,
          3.9474378356133957,
          3.9471679623828906,
          3.946903459629674,
          3.9466442204812444,
          3.9463901401918706,
          3.946141116100256,
          3.9458970475880637,
          3.945657836039263,
          3.9454233848002835,
          3.9451935991409606,
          3.9449683862162574,
          3.944747655028757,
          3.9445313163918874,
          3.9443192828938916,
          3.944111468862505,
          3.9439077903303437,
          3.9437081650009724,
          3.943512512215656,
          3.9433207529207666,
          3.943132809635846,
          3.9429486064222945,
          3.942768068852693,
          3.942591123980726,
          3.9424177003117133,
          3.942247727773714,
          3.9420811376892186,
          3.9419178627474065,
          3.9417578369769353,
          3.9416009957192966,
          3.9414472756026853,
          3.941296614516393,
          3.9411489515857197,
          3.9410042271473658,
          3.940862382725337,
          3.9407233610073056,
          3.940587105821462,
          3.940453562113817,
          3.940322675925955,
          3.9401943943732323,
          3.940068665623408,
          3.939945438875704,
          3.9398246643402786,
          3.93970629321811,
          3.9395902776812712,
          3.9394765708536164,
          3.9393651267918317,
          3.9392559004668772,
          3.939148847745789,
          3.9390439253738494,
          3.938941090957113,
          3.938840302945269,
          3.938741520614859,
          3.9386447040528263,
          3.938549814140377,
          3.938456812537187,
          3.9383656616658995,
          3.9382763246969503,
          3.938188765533684,
          3.9381029487977672,
          3.938018839814894,
          3.9379364046007796,
          3.9378556098474267,
          3.937776422909666,
          3.9376988117919662,
          3.937622745135508,
          3.937548192205514,
          3.9374751228788267,
          3.937403507631741,
          3.9373333175280707,
          3.9372645242074658,
          3.937197099873939,
          3.9371310172846505,
          3.937066249738888,
          3.937002771067287,
          3.9369405556212516,
          3.9368795782625883,
          3.9368198143533664,
          3.936761239745938,
          3.9367038307731956,
          3.9366475642390117,
          3.936592417408858,
          3.9365383680006243,
          3.9364853941756137,
          3.9364334745297214,
          3.9363825880847827,
          3.9363327142800975,
          3.936283832964126,
          3.9362359243863434,
          3.936188969189257,
          3.936142948400593,
          3.9360978434256237,
          3.9360536360396563,
          3.93601030838067,
          3.9359678429420963,
          3.9359262225657514,
          3.935885430434896,
          3.9358454500674434,
          3.9358062653093038,
          3.935767860327851,
          3.935730219605529,
          3.9356933279335817,
          3.9356571704059053,
          3.9356217324130296,
          3.9355869996362136,
          3.9355529580416557,
          3.9355195938748286,
          3.935486893654922,
          3.9354548441693917,
          3.9354234324686233,
          3.9353926458607007,
          3.9353624719062745,
          3.935332898413543,
          3.9353039134333154,
          3.9352755052541943,
          3.9352476623978387,
          3.935220373614324,
          3.935193627877602,
          3.93516741438104,
          3.9351417225330594,
          3.9351165419528544,
          3.935091862466195,
          3.9350676741013206,
          3.9350439670849067,
          3.93502073183812,
          3.9349979589727435,
          3.9349756392873885,
          3.934953763763771,
          3.9349323235630753,
          3.9349113100223723,
          3.93489071465113,
          3.934870529127775,
          3.934850745296334,
          3.9348313551631398,
          3.9348123508935964,
          3.9347937248090155,
          3.93477546938352,
          3.9347575772409895,
          3.934740041152096,
          3.9347228540313717,
          3.934706008934351,
          3.9346894990547594,
          3.934673317721772,
          3.934657458397311,
          3.934641914673407,
          3.934626680269609,
          3.9346117490304455,
          3.934597114922943,
          3.9345827720341777,
          3.9345687145689,
          3.9345549368471815,
          3.934541433302126,
          3.9345281984776164,
          3.9345152270261137,
          3.9345025137064966,
          3.93449005338194,
          3.9344778410178414,
          3.9344658716797887,
          3.934454140531564,
          3.9344426428331882,
          3.93443137393901,
          3.9344203292958264,
          3.934409504441042,
          3.9343988950008675,
          3.9343884966885527,
          3.9343783053026526,
          3.9343683167253323,
          3.9343585269207013,
          3.9343489319331817,
          3.9343395278859137,
          3.9343303109791865,
          3.934321277488904,
          3.934312423765077,
          3.934303746230354,
          3.934295241378572,
          3.9342869057733414,
          3.934278736046654,
          3.934270728897528,
          3.93426288109067,
          3.9342551894551683,
          3.9342476508832123,
          3.93424026232884,
          3.934233020806699,
          3.9342259233908474,
          3.934218967213572,
          3.934212149464224,
          3.934205467388088,
          3.9341989182852672,
          3.9341924995095936,
          3.934186208467555,
          3.9341800426172537,
          3.9341739994673732,
          3.934168076576175,
          3.9341622715505107,
          3.9341565820448583,
          3.9341510057603686,
          3.93414554044394,
          3.934140183887308,
          3.9341349339261518,
          3.934129788439224,
          3.9341247453474857,
          3.934119802613274,
          3.9341149582394723,
          3.9341102102687096,
          3.9341055567825647,
          3.9341009959007938,
          3.9340965257805705,
          3.934092144615739,
          3.9340878506360886,
          3.934083642106633,
          3.9340795173269125,
          3.93407547463031,
          3.934071512383369,
          3.9340676289851437,
          3.9340638228665408,
          3.9340600924896996,
          3.934056436347357,
          3.9340528529622465,
          3.9340493408865003,
          3.934045898701062,
          3.934042525015113,
          3.9340392184655153,
          3.934035977716254,
          3.934032801457904,
          3.9340296884070924,
          3.934026637305994,
          3.9340236469218075,
          3.934020716046266,
          3.9340178434951474,
          3.934015028107797,
          3.9340122687466534,
          3.934009564296798,
          3.934006913665496,
          3.934004315781753,
          3.934001769595899,
          3.9339992740791434,
          3.933996828223171,
          3.9339944310397317,
          3.9339920815602443,
          3.9339897788353984,
          3.933987521934775,
          3.9339853099464768,
          3.9339831419767446,
          3.9339810171496086,
          3.9339789346065346,
          3.933976893506066,
          3.933974893023499,
          3.933972932350533,
          3.9339710106949597,
          3.933969127280333,
          3.9339672813456565,
          3.93396547214508,
          3.9339636989475957,
          3.9339619610367413,
          3.933960257710313,
          3.9339585882800803,
          3.9339569520715094,
          3.933955348423488,
          3.933953776688062,
          3.9339522362301738,
          3.933950726427395,
          3.933949246669693,
          3.933947796359169,
          3.9339463749098234,
          3.93394498174732,
          3.9339436163087504,
          3.93394227804241,
          3.9339409664075675,
          3.933939680874261,
          3.9339384209230652,
          3.9339371860448984,
          3.9339359757408072,
          3.9339347895217673,
          3.933933626908487,
          3.9339324874312105,
          3.933931370629532,
          3.9339302760522066,
          3.93392920325697,
          3.9339281518103584,
          3.933927121287535,
          3.9339261112721156,
          3.933925121356003
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#f2f5fa"
            },
            "error_y": {
             "color": "#f2f5fa"
            },
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "rgb(17,17,17)",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "baxis": {
             "endlinecolor": "#A2B1C6",
             "gridcolor": "#506784",
             "linecolor": "#506784",
             "minorgridcolor": "#506784",
             "startlinecolor": "#A2B1C6"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "line": {
              "color": "#283442"
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#506784"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "header": {
             "fill": {
              "color": "#2a3f5f"
             },
             "line": {
              "color": "rgb(17,17,17)"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#f2f5fa",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#f2f5fa"
          },
          "geo": {
           "bgcolor": "rgb(17,17,17)",
           "lakecolor": "rgb(17,17,17)",
           "landcolor": "rgb(17,17,17)",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#506784"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "dark"
          },
          "paper_bgcolor": "rgb(17,17,17)",
          "plot_bgcolor": "rgb(17,17,17)",
          "polar": {
           "angularaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "bgcolor": "rgb(17,17,17)",
           "radialaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           },
           "yaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           },
           "zaxis": {
            "backgroundcolor": "rgb(17,17,17)",
            "gridcolor": "#506784",
            "gridwidth": 2,
            "linecolor": "#506784",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#C8D4E3"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#f2f5fa"
           }
          },
          "sliderdefaults": {
           "bgcolor": "#C8D4E3",
           "bordercolor": "rgb(17,17,17)",
           "borderwidth": 1,
           "tickwidth": 0
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           },
           "bgcolor": "rgb(17,17,17)",
           "caxis": {
            "gridcolor": "#506784",
            "linecolor": "#506784",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "updatemenudefaults": {
           "bgcolor": "#506784",
           "borderwidth": 0
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#283442",
           "linecolor": "#506784",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#283442",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "font": {
          "color": "#41BEE9"
         },
         "text": "Cost vs Iteration"
        },
        "xaxis": {
         "anchor": "y",
         "color": "#41BEE9",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Iterations"
         }
        },
        "yaxis": {
         "anchor": "x",
         "color": "#41BEE9",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Cost"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = LinearRegression(0.01)\n",
    "lr.fit(X_train, y_train, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9ce1a38e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1, 2]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Create and fit the model using Gradient Descent\u001b[39;00m\n\u001b[1;32m     11\u001b[0m sgd_model \u001b[38;5;241m=\u001b[39m SGDRegressor(max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, tol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m sgd_model\u001b[38;5;241m.\u001b[39mfit(testX, testY)  \u001b[38;5;66;03m# y needs to be flattened\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[1;32m     15\u001b[0m y_sgd_pred \u001b[38;5;241m=\u001b[39m sgd_model\u001b[38;5;241m.\u001b[39mpredict(testX)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1647\u001b[0m, in \u001b[0;36mBaseSGDRegressor.fit\u001b[0;34m(self, X, y, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[1;32m   1621\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit linear model with Stochastic Gradient Descent.\u001b[39;00m\n\u001b[1;32m   1622\u001b[0m \n\u001b[1;32m   1623\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1643\u001b[0m \u001b[38;5;124;03m    Fitted `SGDRegressor` estimator.\u001b[39;00m\n\u001b[1;32m   1644\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1645\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_more_validate_params()\n\u001b[0;32m-> 1647\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[1;32m   1648\u001b[0m     X,\n\u001b[1;32m   1649\u001b[0m     y,\n\u001b[1;32m   1650\u001b[0m     alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha,\n\u001b[1;32m   1651\u001b[0m     C\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m,\n\u001b[1;32m   1652\u001b[0m     loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss,\n\u001b[1;32m   1653\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearning_rate,\n\u001b[1;32m   1654\u001b[0m     coef_init\u001b[38;5;241m=\u001b[39mcoef_init,\n\u001b[1;32m   1655\u001b[0m     intercept_init\u001b[38;5;241m=\u001b[39mintercept_init,\n\u001b[1;32m   1656\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m   1657\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1590\u001b[0m, in \u001b[0;36mBaseSGDRegressor._fit\u001b[0;34m(self, X, y, alpha, C, loss, learning_rate, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[1;32m   1587\u001b[0m \u001b[38;5;66;03m# Clear iteration count for multiple call to fit.\u001b[39;00m\n\u001b[1;32m   1588\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mt_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n\u001b[0;32m-> 1590\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_partial_fit(\n\u001b[1;32m   1591\u001b[0m     X,\n\u001b[1;32m   1592\u001b[0m     y,\n\u001b[1;32m   1593\u001b[0m     alpha,\n\u001b[1;32m   1594\u001b[0m     C,\n\u001b[1;32m   1595\u001b[0m     loss,\n\u001b[1;32m   1596\u001b[0m     learning_rate,\n\u001b[1;32m   1597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iter,\n\u001b[1;32m   1598\u001b[0m     sample_weight,\n\u001b[1;32m   1599\u001b[0m     coef_init,\n\u001b[1;32m   1600\u001b[0m     intercept_init,\n\u001b[1;32m   1601\u001b[0m )\n\u001b[1;32m   1603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1604\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtol \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1605\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtol \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39minf\n\u001b[1;32m   1606\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iter\n\u001b[1;32m   1607\u001b[0m ):\n\u001b[1;32m   1608\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1609\u001b[0m         (\n\u001b[1;32m   1610\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMaximum number of iteration reached before \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1614\u001b[0m         ConvergenceWarning,\n\u001b[1;32m   1615\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_stochastic_gradient.py:1467\u001b[0m, in \u001b[0;36mBaseSGDRegressor._partial_fit\u001b[0;34m(self, X, y, alpha, C, loss, learning_rate, max_iter, sample_weight, coef_init, intercept_init)\u001b[0m\n\u001b[1;32m   1453\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_partial_fit\u001b[39m(\n\u001b[1;32m   1454\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1455\u001b[0m     X,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1464\u001b[0m     intercept_init,\n\u001b[1;32m   1465\u001b[0m ):\n\u001b[1;32m   1466\u001b[0m     first_call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoef_\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1467\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m validate_data(\n\u001b[1;32m   1468\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1469\u001b[0m         X,\n\u001b[1;32m   1470\u001b[0m         y,\n\u001b[1;32m   1471\u001b[0m         accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1472\u001b[0m         copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1473\u001b[0m         order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1474\u001b[0m         dtype\u001b[38;5;241m=\u001b[39m[np\u001b[38;5;241m.\u001b[39mfloat64, np\u001b[38;5;241m.\u001b[39mfloat32],\n\u001b[1;32m   1475\u001b[0m         accept_large_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1476\u001b[0m         reset\u001b[38;5;241m=\u001b[39mfirst_call,\n\u001b[1;32m   1477\u001b[0m     )\n\u001b[1;32m   1478\u001b[0m     y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mastype(X\u001b[38;5;241m.\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1480\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m first_call:\n\u001b[1;32m   1481\u001b[0m         \u001b[38;5;66;03m# TODO(1.7) remove 0 from average parameter constraint\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:2961\u001b[0m, in \u001b[0;36mvalidate_data\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2959\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m   2960\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2961\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[1;32m   2962\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m   2964\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:1389\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1370\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[1;32m   1371\u001b[0m     X,\n\u001b[1;32m   1372\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1384\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1385\u001b[0m )\n\u001b[1;32m   1387\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m-> 1389\u001b[0m check_consistent_length(X, y)\n\u001b[1;32m   1391\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:475\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    473\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 475\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    476\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    477\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    478\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1, 2]"
     ]
    }
   ],
   "source": [
    "testX = np.array([[1,2]])\n",
    "testY = np.array([2,3])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# Create and fit the model using Gradient Descent\n",
    "sgd_model = SGDRegressor(max_iter=1000, tol=1e-3)\n",
    "sgd_model.fit(testX, testY)  # y needs to be flattened\n",
    "\n",
    "# Make predictions\n",
    "y_sgd_pred = sgd_model.predict(testX)\n",
    "\n",
    "# Visualize the result\n",
    "plt.scatter(testX, testY, color='blue', label='Data points')\n",
    "plt.plot(testX, y_sgd_pred, color='green', label='GD Fit')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Print out the coefficients\n",
    "print(f'Intercept: {sgd_model.intercept_}')\n",
    "print(f'Coefficient: {sgd_model.coef_}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae4fe913",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "california = fetch_california_housing()\n",
    "X = california.data\n",
    "y = california.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11b81cb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[   8.3252    ,   41.        ,    6.98412698, ...,    2.55555556,\n",
       "           37.88      , -122.23      ],\n",
       "        [   8.3014    ,   21.        ,    6.23813708, ...,    2.10984183,\n",
       "           37.86      , -122.22      ],\n",
       "        [   7.2574    ,   52.        ,    8.28813559, ...,    2.80225989,\n",
       "           37.85      , -122.24      ],\n",
       "        ...,\n",
       "        [   1.7       ,   17.        ,    5.20554273, ...,    2.3256351 ,\n",
       "           39.43      , -121.22      ],\n",
       "        [   1.8672    ,   18.        ,    5.32951289, ...,    2.12320917,\n",
       "           39.43      , -121.32      ],\n",
       "        [   2.3886    ,   16.        ,    5.25471698, ...,    2.61698113,\n",
       "           39.37      , -121.24      ]]),\n",
       " 'target': array([4.526, 3.585, 3.521, ..., 0.923, 0.847, 0.894]),\n",
       " 'frame': None,\n",
       " 'target_names': ['MedHouseVal'],\n",
       " 'feature_names': ['MedInc',\n",
       "  'HouseAge',\n",
       "  'AveRooms',\n",
       "  'AveBedrms',\n",
       "  'Population',\n",
       "  'AveOccup',\n",
       "  'Latitude',\n",
       "  'Longitude'],\n",
       " 'DESCR': '.. _california_housing_dataset:\\n\\nCalifornia Housing dataset\\n--------------------------\\n\\n**Data Set Characteristics:**\\n\\n:Number of Instances: 20640\\n\\n:Number of Attributes: 8 numeric, predictive attributes and the target\\n\\n:Attribute Information:\\n    - MedInc        median income in block group\\n    - HouseAge      median house age in block group\\n    - AveRooms      average number of rooms per household\\n    - AveBedrms     average number of bedrooms per household\\n    - Population    block group population\\n    - AveOccup      average number of household members\\n    - Latitude      block group latitude\\n    - Longitude     block group longitude\\n\\n:Missing Attribute Values: None\\n\\nThis dataset was obtained from the StatLib repository.\\nhttps://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\\n\\nThe target variable is the median house value for California districts,\\nexpressed in hundreds of thousands of dollars ($100,000).\\n\\nThis dataset was derived from the 1990 U.S. census, using one row per census\\nblock group. A block group is the smallest geographical unit for which the U.S.\\nCensus Bureau publishes sample data (a block group typically has a population\\nof 600 to 3,000 people).\\n\\nA household is a group of people residing within a home. Since the average\\nnumber of rooms and bedrooms in this dataset are provided per household, these\\ncolumns may take surprisingly large values for block groups with few households\\nand many empty houses, such as vacation resorts.\\n\\nIt can be downloaded/loaded using the\\n:func:`sklearn.datasets.fetch_california_housing` function.\\n\\n.. rubric:: References\\n\\n- Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\\n  Statistics and Probability Letters, 33 (1997) 291-297\\n'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "california"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f59d0c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28.95283303] [49.93986917]\n"
     ]
    }
   ],
   "source": [
    "#######################\n",
    "\n",
    "def predict(x, w1, w0):\n",
    "    return w1 * x + w0\n",
    "def compute_coefficient(x, y):\n",
    "    n = len(x)\n",
    "    x_mean = np.mean(x)\n",
    "    y_mean = np.mean(y)\n",
    "\n",
    "    numerator = 0\n",
    "    denominator = 0\n",
    "\n",
    "    for i in range(n):\n",
    "        numerator += (x[i] - x_mean) * (y[i] - y_mean)\n",
    "        denominator += (x[i] - x_mean) ** 2\n",
    "\n",
    "    # Calculate coefficients\n",
    "    slope = numerator / denominator\n",
    "    intercept = y_mean - slope * x_mean\n",
    "\n",
    "    return slope, intercept\n",
    "\n",
    "\n",
    "w1, w0 = compute_coefficient(X_train, y_train)\n",
    "# display the value of predicted coefficients\n",
    "print(w1,w0)\n",
    "\n",
    "#####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2df5e71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "699"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8bd264dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-29T06:12:59.304828Z",
     "iopub.status.busy": "2023-09-29T06:12:59.303139Z",
     "iopub.status.idle": "2023-09-29T06:12:59.310404Z",
     "shell.execute_reply": "2023-09-29T06:12:59.309078Z"
    },
    "papermill": {
     "duration": 0.018791,
     "end_time": "2023-09-29T06:12:59.313354",
     "exception": false,
     "start_time": "2023-09-29T06:12:59.294563",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lr.save_model('model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e882061",
   "metadata": {
    "papermill": {
     "duration": 0.006781,
     "end_time": "2023-09-29T06:12:59.327962",
     "exception": false,
     "start_time": "2023-09-29T06:12:59.321181",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id=\"6\"></a>\n",
    "<h1 style='background:#00EFFF;border:0; color:black;\n",
    "    box-shadow: 10px 10px 5px 0px rgba(0,0,0,0.75);\n",
    "    transform: rotateX(10deg);\n",
    "    '><center style='color: #000000;'>Evaluation</center></h1>\n",
    "    \n",
    "    \n",
    "    \n",
    "# Evaluation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a8adb5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-29T06:12:59.344846Z",
     "iopub.status.busy": "2023-09-29T06:12:59.344365Z",
     "iopub.status.idle": "2023-09-29T06:12:59.349982Z",
     "shell.execute_reply": "2023-09-29T06:12:59.348818Z"
    },
    "papermill": {
     "duration": 0.017301,
     "end_time": "2023-09-29T06:12:59.352514",
     "exception": false,
     "start_time": "2023-09-29T06:12:59.335213",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = LinearRegression.load_model(\"model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c79e7a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28.94793048]\n",
      "49.9314114070449\n"
     ]
    }
   ],
   "source": [
    "print(model.W)\n",
    "print(model.b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df37a304",
   "metadata": {
    "papermill": {
     "duration": 0.006837,
     "end_time": "2023-09-29T06:12:59.366482",
     "exception": false,
     "start_time": "2023-09-29T06:12:59.359645",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 1. Mean Squared Error (MSE)\n",
    "\n",
    "**Formula:**\n",
    "$$\n",
    "\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_{\\text{true}_i} - y_{\\text{pred}_i})^2\n",
    "$$\n",
    "\n",
    "**Description:**\n",
    "- **Mean Squared Error (MSE)** is a widely used metric for evaluating the accuracy of regression models.\n",
    "- It measures the average squared difference between the predicted values ($y_{\\text{pred}}$) and the actual target values ($y_{\\text{true}}$).\n",
    "- The squared differences are averaged across all data points in the dataset.\n",
    "\n",
    "**Interpretation:**\n",
    "- A lower MSE indicates a better fit of the model to the data, as it means the model's predictions are closer to the actual values.\n",
    "- MSE is sensitive to outliers because the squared differences magnify the impact of large errors.\n",
    "\n",
    "### 2. Root Mean Squared Error (RMSE)\n",
    "\n",
    "**Formula:**\n",
    "$$\n",
    "\\text{RMSE} = \\sqrt{\\text{MSE}}\n",
    "$$\n",
    "\n",
    "**Description:**\n",
    "- **Root Mean Squared Error (RMSE)** is a variant of MSE that provides the square root of the average squared difference between predicted and actual values.\n",
    "- It is often preferred because it is in the same unit as the target variable, making it more interpretable.\n",
    "\n",
    "**Interpretation:**\n",
    "- Like MSE, a lower RMSE indicates a better fit of the model to the data.\n",
    "- RMSE is also sensitive to outliers due to the square root operation.\n",
    "\n",
    "### 3. R-squared ($R^2$)\n",
    "\n",
    "**Formula:**\n",
    "$$\n",
    "R^2 = 1 - \\frac{\\text{SSR}}{\\text{SST}}\n",
    "$$\n",
    "\n",
    "**Description:**\n",
    "- **R-squared ($R^2$)**, also known as the coefficient of determination, measures the proportion of the variance in the dependent variable ($y_{\\text{true}}$) that is predictable from the independent variable(s) ($y_{\\text{pred}}$) in a regression model.\n",
    "- It ranges from 0 to 1, where 0 indicates that the model does not explain any variance, and 1 indicates a perfect fit.\n",
    "\n",
    "**Interpretation:**\n",
    "- A higher $R^2$ value suggests that the model explains a larger proportion of the variance in the target variable.\n",
    "- However, $R^2$ does not provide information about the goodness of individual predictions or whether the model is overfitting or underfitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c3f678e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-29T06:12:59.383865Z",
     "iopub.status.busy": "2023-09-29T06:12:59.383391Z",
     "iopub.status.idle": "2023-09-29T06:12:59.393023Z",
     "shell.execute_reply": "2023-09-29T06:12:59.391558Z"
    },
    "papermill": {
     "duration": 0.021248,
     "end_time": "2023-09-29T06:12:59.395535",
     "exception": false,
     "start_time": "2023-09-29T06:12:59.374287",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RegressionMetrics:\n",
    "    @staticmethod\n",
    "    def mean_squared_error(y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Calculate the Mean Squared Error (MSE).\n",
    "\n",
    "        Args:\n",
    "            y_true (numpy.ndarray): The true target values.\n",
    "            y_pred (numpy.ndarray): The predicted target values.\n",
    "\n",
    "        Returns:\n",
    "            float: The Mean Squared Error.\n",
    "        \"\"\"\n",
    "        assert len(y_true) == len(y_pred), \"Input arrays must have the same length.\"\n",
    "        mse = np.mean((y_true - y_pred) ** 2)\n",
    "        return mse\n",
    "\n",
    "    @staticmethod\n",
    "    def root_mean_squared_error(y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Calculate the Root Mean Squared Error (RMSE).\n",
    "\n",
    "        Args:\n",
    "            y_true (numpy.ndarray): The true target values.\n",
    "            y_pred (numpy.ndarray): The predicted target values.\n",
    "\n",
    "        Returns:\n",
    "            float: The Root Mean Squared Error.\n",
    "        \"\"\"\n",
    "        assert len(y_true) == len(y_pred), \"Input arrays must have the same length.\"\n",
    "        mse = RegressionMetrics.mean_squared_error(y_true, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        return rmse\n",
    "\n",
    "    @staticmethod\n",
    "    def r_squared(y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Calculate the R-squared (R^2) coefficient of determination.\n",
    "\n",
    "        Args:\n",
    "            y_true (numpy.ndarray): The true target values.\n",
    "            y_pred (numpy.ndarray): The predicted target values.\n",
    "\n",
    "        Returns:\n",
    "            float: The R-squared (R^2) value.\n",
    "        \"\"\"\n",
    "        assert len(y_true) == len(y_pred), \"Input arrays must have the same length.\"\n",
    "        mean_y = np.mean(y_true)\n",
    "        ss_total = np.sum((y_true - mean_y) ** 2)\n",
    "        ss_residual = np.sum((y_true - y_pred) ** 2)\n",
    "        r2 = 1 - (ss_residual / ss_total)\n",
    "        return r2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a607083c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-29T06:12:59.411638Z",
     "iopub.status.busy": "2023-09-29T06:12:59.411089Z",
     "iopub.status.idle": "2023-09-29T06:12:59.419589Z",
     "shell.execute_reply": "2023-09-29T06:12:59.417959Z"
    },
    "papermill": {
     "duration": 0.020038,
     "end_time": "2023-09-29T06:12:59.422700",
     "exception": false,
     "start_time": "2023-09-29T06:12:59.402662",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 9.442669163015285\n",
      "Root Mean Squared Error (RMSE): 3.072892637730008\n",
      "R-squared (Coefficient of Determination): 0.988789873045453\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "mse_value = RegressionMetrics.mean_squared_error(y_test, y_pred)\n",
    "rmse_value = RegressionMetrics.root_mean_squared_error(y_test, y_pred)\n",
    "r_squared_value = RegressionMetrics.r_squared(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse_value}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse_value}\")\n",
    "print(f\"R-squared (Coefficient of Determination): {r_squared_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79a88ca",
   "metadata": {
    "papermill": {
     "duration": 0.006652,
     "end_time": "2023-09-29T06:12:59.436584",
     "exception": false,
     "start_time": "2023-09-29T06:12:59.429932",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id=\"7\"></a>\n",
    "<h1 style='background:#00EFFF;border:0; color:black;\n",
    "    box-shadow: 10px 10px 5px 0px rgba(0,0,0,0.75);\n",
    "    transform: rotateX(10deg);\n",
    "    '><center style='color: #000000;'>Thank You</center></h1>\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "# Thank You\n",
    "\n",
    "**Thank you for going through the notebook if you haev any feedback please let me know**\n",
    "\n",
    "**Now that we know how to implement Linear Regression from scratch let's check [sklearn implementation](https://www.kaggle.com/code/fareselmenshawii/linear-regression)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919d3fc0",
   "metadata": {
    "papermill": {
     "duration": 0.00672,
     "end_time": "2023-09-29T06:12:59.450369",
     "exception": false,
     "start_time": "2023-09-29T06:12:59.443649",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"padding:10px; \n",
    "            color:#333333;\n",
    "            margin:10px;\n",
    "            font-size:150%;\n",
    "            display:fill;\n",
    "            border-radius:1px;\n",
    "            border-style:solid;\n",
    "            border-color:#666666;\n",
    "            background-color:#F9F9F9;\n",
    "            overflow:hidden;\">\n",
    "    <center>\n",
    "        <a id='top'></a>\n",
    "        <b>Machine Learning From Scratch Series</b>\n",
    "    </center>\n",
    "    <br>\n",
    "    <ul>\n",
    "        <li>\n",
    "            <a href=\"https://www.kaggle.com/code/fareselmenshawii/linear-regression-from-scratch\" style=\"color:#0072B2\">1 - Linear Regression</a>\n",
    "        </li>\n",
    "        <li>\n",
    "            <a href=\"https://www.kaggle.com/code/fareselmenshawii/logistic-regression-from-scratch\" style=\"color:#0072B2\">2 -  Logistic Regression</a>\n",
    "        </li>\n",
    "        <li>\n",
    "            <a href=\"https://www.kaggle.com/code/fareselmenshawii/kmeans-from-scratch\" style=\"color:#0072B2\">3 - KMeans</a>\n",
    "        </li>\n",
    "        <li>\n",
    "            <a href=\"https://www.kaggle.com/code/fareselmenshawii/decision-tree-classifier-from-scratch\" style=\"color:#0072B2\">4 - Decision Trees</a>\n",
    "        </li> \n",
    "        <li>\n",
    "            <a href=\"https://www.kaggle.com/code/fareselmenshawii/random-forest-classifier-from-scratch\" style=\"color:#0072B2\">5 -  Random Forest</a>\n",
    "        </li>\n",
    "        <li>\n",
    "            <a href=\"https://www.kaggle.com/code/fareselmenshawii/knn-from-scratch\" style=\"color:#0072B2\">6 - KNearestNeighbor</a>\n",
    "        </li>\n",
    "        <li>\n",
    "            <a href=\"https://www.kaggle.com/code/fareselmenshawii/pca-from-scratch?scriptVersionId=121402593\" style=\"color:#0072B2\">7 - PCA</a>\n",
    "        </li>\n",
    "        <li>\n",
    "            <a href=\"https://www.kaggle.com/code/fareselmenshawii/svm-from-scratch\" style=\"color:#0072B2\">8 - SVM</a>\n",
    "        </li>\n",
    "        <li>\n",
    "            <a href=\"https://www.kaggle.com/code/fareselmenshawii/naive-bayes-from-scratch\" style=\"color:#0072B2\">9 - Naive Baye</a>\n",
    "        </li>\n",
    "        <li>\n",
    "            <a href=\"https://www.kaggle.com/code/fareselmenshawii/optimized-neural-network-from-scratch\" style=\"color:#0072B2\">10 - Optimized Neural Network</a>\n",
    "        </li>\n",
    "        <li>\n",
    "            <a href=\"https://www.kaggle.com/code/fareselmenshawii/neural-network-from-scratch\" style=\"color:#0072B2\">11 - Neural Network</a>\n",
    "        </li>\n",
    "        <li>\n",
    "            <a href=\"https://www.kaggle.com/code/fareselmenshawii/cnn-from-scratch\" style=\"color:#0072B2\">12 - CNN</a>\n",
    "        </li>\n",
    "        <li>\n",
    "            <a href=\"https://www.kaggle.com/code/fareselmenshawii/rnn-from-scratch\" style=\"color:#0072B2\">13 - RNN</a>\n",
    "        </li>\n",
    "        <li>\n",
    "            <a href=\"https://www.kaggle.com/code/fareselmenshawii/lstm-from-scratch\" style=\"color:#0072B2\">14 - LSTM</a>\n",
    "        </li>\n",
    "        <li>\n",
    "            <a href=\"https://www.kaggle.com/code/fareselmenshawii/gru-from-scratch\" style=\"color:#0072B2\">15 - GRU</a>\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 16.874252,
   "end_time": "2023-09-29T06:13:00.684184",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-09-29T06:12:43.809932",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
